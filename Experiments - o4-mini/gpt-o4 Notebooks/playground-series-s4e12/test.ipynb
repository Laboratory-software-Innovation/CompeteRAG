{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with an Insurance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - Attempt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 21:42:42.139689: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 24s - 2ms/step - loss: 1.7048 - mae: 0.9848 - rmse: 1.3057 - val_loss: 1.1586 - val_mae: 0.7775 - val_rmse: 1.0764\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 22s - 1ms/step - loss: 1.1823 - mae: 0.7873 - rmse: 1.0873 - val_loss: 1.1495 - val_mae: 0.7651 - val_rmse: 1.0721\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 23s - 2ms/step - loss: 1.1640 - mae: 0.7752 - rmse: 1.0789 - val_loss: 1.1468 - val_mae: 0.7655 - val_rmse: 1.0709\n",
      "Epoch 4/100\n",
      "15000/15000 - 24s - 2ms/step - loss: 1.1606 - mae: 0.7728 - rmse: 1.0773 - val_loss: 1.1469 - val_mae: 0.7657 - val_rmse: 1.0709\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 26s - 2ms/step - loss: 1.1594 - mae: 0.7721 - rmse: 1.0768 - val_loss: 1.1440 - val_mae: 0.7640 - val_rmse: 1.0696\n",
      "Epoch 6/100\n",
      "15000/15000 - 24s - 2ms/step - loss: 1.1592 - mae: 0.7717 - rmse: 1.0766 - val_loss: 1.1451 - val_mae: 0.7636 - val_rmse: 1.0701\n",
      "Epoch 7/100\n",
      "15000/15000 - 24s - 2ms/step - loss: 1.1584 - mae: 0.7713 - rmse: 1.0763 - val_loss: 1.1451 - val_mae: 0.7645 - val_rmse: 1.0701\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 24s - 2ms/step - loss: 1.1580 - mae: 0.7711 - rmse: 1.0761 - val_loss: 1.1438 - val_mae: 0.7638 - val_rmse: 1.0695\n",
      "Epoch 9/100\n",
      "15000/15000 - 24s - 2ms/step - loss: 1.1578 - mae: 0.7709 - rmse: 1.0760 - val_loss: 1.1441 - val_mae: 0.7640 - val_rmse: 1.0696\n",
      "Epoch 10/100\n",
      "15000/15000 - 24s - 2ms/step - loss: 1.1575 - mae: 0.7707 - rmse: 1.0759 - val_loss: 1.1440 - val_mae: 0.7642 - val_rmse: 1.0696\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 26s - 2ms/step - loss: 1.1572 - mae: 0.7707 - rmse: 1.0757 - val_loss: 1.1435 - val_mae: 0.7651 - val_rmse: 1.0694\n",
      "Epoch 12/100\n",
      "15000/15000 - 26s - 2ms/step - loss: 1.1571 - mae: 0.7706 - rmse: 1.0757 - val_loss: 1.1448 - val_mae: 0.7640 - val_rmse: 1.0700\n",
      "Epoch 13/100\n",
      "15000/15000 - 23s - 2ms/step - loss: 1.1570 - mae: 0.7706 - rmse: 1.0756 - val_loss: 1.1436 - val_mae: 0.7644 - val_rmse: 1.0694\n",
      "Epoch 14/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1566 - mae: 0.7704 - rmse: 1.0755 - val_loss: 1.1444 - val_mae: 0.7643 - val_rmse: 1.0697\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 22s - 1ms/step - loss: 1.1569 - mae: 0.7705 - rmse: 1.0756 - val_loss: 1.1430 - val_mae: 0.7635 - val_rmse: 1.0691\n",
      "Epoch 16/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1565 - mae: 0.7703 - rmse: 1.0754 - val_loss: 1.1440 - val_mae: 0.7636 - val_rmse: 1.0696\n",
      "Epoch 17/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1568 - mae: 0.7704 - rmse: 1.0756 - val_loss: 1.1437 - val_mae: 0.7637 - val_rmse: 1.0694\n",
      "Epoch 18/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1566 - mae: 0.7704 - rmse: 1.0754 - val_loss: 1.1436 - val_mae: 0.7637 - val_rmse: 1.0694\n",
      "Epoch 19/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1563 - mae: 0.7701 - rmse: 1.0753 - val_loss: 1.1433 - val_mae: 0.7633 - val_rmse: 1.0692\n",
      "Epoch 20/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1562 - mae: 0.7702 - rmse: 1.0753 - val_loss: 1.1436 - val_mae: 0.7629 - val_rmse: 1.0694\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 24s - 2ms/step - loss: 1.1561 - mae: 0.7702 - rmse: 1.0752 - val_loss: 1.1429 - val_mae: 0.7641 - val_rmse: 1.0691\n",
      "Epoch 22/100\n",
      "15000/15000 - 26s - 2ms/step - loss: 1.1560 - mae: 0.7701 - rmse: 1.0752 - val_loss: 1.1435 - val_mae: 0.7637 - val_rmse: 1.0694\n",
      "Epoch 23/100\n",
      "15000/15000 - 26s - 2ms/step - loss: 1.1562 - mae: 0.7702 - rmse: 1.0753 - val_loss: 1.1443 - val_mae: 0.7651 - val_rmse: 1.0697\n",
      "Epoch 24/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1562 - mae: 0.7702 - rmse: 1.0752 - val_loss: 1.1441 - val_mae: 0.7644 - val_rmse: 1.0696\n",
      "Epoch 25/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1558 - mae: 0.7701 - rmse: 1.0751 - val_loss: 1.1434 - val_mae: 0.7644 - val_rmse: 1.0693\n",
      "Epoch 26/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1557 - mae: 0.7700 - rmse: 1.0750 - val_loss: 1.1429 - val_mae: 0.7628 - val_rmse: 1.0691\n",
      "Epoch 27/100\n",
      "15000/15000 - 23s - 2ms/step - loss: 1.1557 - mae: 0.7701 - rmse: 1.0751 - val_loss: 1.1431 - val_mae: 0.7640 - val_rmse: 1.0692\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 22s - 1ms/step - loss: 1.1557 - mae: 0.7700 - rmse: 1.0750 - val_loss: 1.1428 - val_mae: 0.7637 - val_rmse: 1.0690\n",
      "Epoch 29/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1555 - mae: 0.7700 - rmse: 1.0749 - val_loss: 1.1430 - val_mae: 0.7635 - val_rmse: 1.0691\n",
      "Epoch 30/100\n",
      "15000/15000 - 23s - 2ms/step - loss: 1.1555 - mae: 0.7700 - rmse: 1.0750 - val_loss: 1.1430 - val_mae: 0.7625 - val_rmse: 1.0691\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 22s - 1ms/step - loss: 1.1555 - mae: 0.7699 - rmse: 1.0749 - val_loss: 1.1425 - val_mae: 0.7638 - val_rmse: 1.0689\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 22s - 1ms/step - loss: 1.1556 - mae: 0.7699 - rmse: 1.0750 - val_loss: 1.1424 - val_mae: 0.7630 - val_rmse: 1.0688\n",
      "Epoch 33/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1554 - mae: 0.7699 - rmse: 1.0749 - val_loss: 1.1425 - val_mae: 0.7636 - val_rmse: 1.0689\n",
      "Epoch 34/100\n",
      "15000/15000 - 21s - 1ms/step - loss: 1.1551 - mae: 0.7697 - rmse: 1.0748 - val_loss: 1.1427 - val_mae: 0.7632 - val_rmse: 1.0690\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 19s - 1ms/step - loss: 1.1553 - mae: 0.7699 - rmse: 1.0748 - val_loss: 1.1423 - val_mae: 0.7635 - val_rmse: 1.0688\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 19s - 1ms/step - loss: 1.1557 - mae: 0.7699 - rmse: 1.0750 - val_loss: 1.1421 - val_mae: 0.7614 - val_rmse: 1.0687\n",
      "Epoch 37/100\n",
      "15000/15000 - 19s - 1ms/step - loss: 1.1553 - mae: 0.7698 - rmse: 1.0749 - val_loss: 1.1423 - val_mae: 0.7640 - val_rmse: 1.0688\n",
      "Epoch 38/100\n",
      "15000/15000 - 20s - 1ms/step - loss: 1.1550 - mae: 0.7697 - rmse: 1.0747 - val_loss: 1.1430 - val_mae: 0.7636 - val_rmse: 1.0691\n",
      "Epoch 39/100\n",
      "15000/15000 - 19s - 1ms/step - loss: 1.1550 - mae: 0.7697 - rmse: 1.0747 - val_loss: 1.1435 - val_mae: 0.7637 - val_rmse: 1.0693\n",
      "Epoch 40/100\n",
      "15000/15000 - 20s - 1ms/step - loss: 1.1551 - mae: 0.7698 - rmse: 1.0748 - val_loss: 1.1440 - val_mae: 0.7633 - val_rmse: 1.0696\n",
      "Epoch 41/100\n",
      "15000/15000 - 21s - 1ms/step - loss: 1.1551 - mae: 0.7697 - rmse: 1.0748 - val_loss: 1.1426 - val_mae: 0.7642 - val_rmse: 1.0689\n",
      "Epoch 42/100\n",
      "15000/15000 - 21s - 1ms/step - loss: 1.1554 - mae: 0.7698 - rmse: 1.0749 - val_loss: 1.1432 - val_mae: 0.7628 - val_rmse: 1.0692\n",
      "Epoch 43/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1551 - mae: 0.7697 - rmse: 1.0747 - val_loss: 1.1435 - val_mae: 0.7639 - val_rmse: 1.0693\n",
      "Epoch 44/100\n",
      "15000/15000 - 20s - 1ms/step - loss: 1.1552 - mae: 0.7698 - rmse: 1.0748 - val_loss: 1.1429 - val_mae: 0.7633 - val_rmse: 1.0691\n",
      "Epoch 45/100\n",
      "15000/15000 - 20s - 1ms/step - loss: 1.1554 - mae: 0.7698 - rmse: 1.0749 - val_loss: 1.1437 - val_mae: 0.7637 - val_rmse: 1.0695\n",
      "Epoch 46/100\n",
      "15000/15000 - 21s - 1ms/step - loss: 1.1552 - mae: 0.7698 - rmse: 1.0748 - val_loss: 1.1434 - val_mae: 0.7629 - val_rmse: 1.0693\n",
      "\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 596us/step\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "import os, random, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import all_estimators\n",
    "# scikit-learn has no global seed; we set seeds in train_test_split\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# Load Data\n",
    "df_train = pd.read_csv('playground-series-s4e12/train.csv')\n",
    "df_test = pd.read_csv('playground-series-s4e12/test.csv')\n",
    "# Identify id and target columns\n",
    "id_col = 'id'\n",
    "target_columns = ['Premium Amount']\n",
    "\n",
    "# Combine and encode target\n",
    "df = df_train.copy()\n",
    "y_values = df[target_columns].astype(float).values\n",
    "# Use log1p if all non-negative\n",
    "if np.all(y_values >= 0):\n",
    "    y_enc = np.log1p(y_values)\n",
    "else:\n",
    "    y_enc = y_values\n",
    "\n",
    "# Prepare features\n",
    "drop_cols = [id_col] + target_columns\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "# Testing set\n",
    "X_test = df_test.drop(columns=drop_cols, errors='ignore')\n",
    "test_ids = df_test[id_col]\n",
    "\n",
    "# Feature engineering: drop cols with all missing\n",
    "non_null_cols = X.columns[X.notna().any()].tolist()\n",
    "X = X[non_null_cols]\n",
    "X_test = X_test[non_null_cols]\n",
    "# Identify categorical vs numeric\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# Drop high-cardinality categorical cols\n",
    "high_card = [c for c in categorical_cols if X[c].nunique() > 50]\n",
    "for c in high_card:\n",
    "    X.drop(columns=c, inplace=True)\n",
    "    X_test.drop(columns=c, inplace=True)\n",
    "categorical_cols = [c for c in categorical_cols if c not in high_card]\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "df_train_proc = preprocessor.fit_transform(X)\n",
    "df_test_proc = preprocessor.transform(X_test)\n",
    "n_samples, n_features = df_train_proc.shape\n",
    "\n",
    "# Build model (small dataset branch)\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "hidden_units = [min(n_features*2, 128), min(n_features, 64)]\n",
    "model = models.Sequential()\n",
    "for units in hidden_units:\n",
    "    model.add(layers.Dense(units, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[RootMeanSquaredError(name='rmse'), MeanAbsoluteError(name='mae')]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Training\n",
    "time_start = time.time()\n",
    "history = model.fit(\n",
    "    df_train_proc, y_enc,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "time_duration = time.time() - time_start\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'training_loss': history.history['loss'][-1],\n",
    "    'validation_loss': history.history['val_loss'][-1],\n",
    "    'training_rmse': history.history['rmse'][-1],\n",
    "    'validation_rmse': history.history['val_rmse'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "raw_preds = model.predict(df_test_proc)\n",
    "# Reverse log\n",
    "final = np.expm1(np.clip(raw_preds, a_min=None, a_max=20))\n",
    "# Ensure 2D\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1,1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 21m 06s]\n",
      "val_loss: 1.1446022987365723\n",
      "\n",
      "Best val_loss So Far: 1.1321594715118408\n",
      "Total elapsed time: 04h 26m 48s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:10:00.840071: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 496 bytes spill stores, 496 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:00.889840: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:00.943026: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.026897: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.084641: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42_0', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.105375: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 420 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.317834: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 988 bytes spill stores, 988 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.352327: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 1984 bytes spill stores, 1996 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.622911: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 2744 bytes spill stores, 2492 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.707984: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 3160 bytes spill stores, 2988 bytes spill loads\n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 82s - 5ms/step - loss: 1.2421 - mae: 0.8094 - rmse: 1.1145 - val_loss: 1.1509 - val_mae: 0.7695 - val_rmse: 1.0728\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 68s - 5ms/step - loss: 1.1792 - mae: 0.7825 - rmse: 1.0859 - val_loss: 1.1480 - val_mae: 0.7706 - val_rmse: 1.0714\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 70s - 5ms/step - loss: 1.1715 - mae: 0.7782 - rmse: 1.0824 - val_loss: 1.1471 - val_mae: 0.7699 - val_rmse: 1.0710\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 80s - 5ms/step - loss: 1.1689 - mae: 0.7769 - rmse: 1.0811 - val_loss: 1.1441 - val_mae: 0.7692 - val_rmse: 1.0696\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 71s - 5ms/step - loss: 1.1665 - mae: 0.7758 - rmse: 1.0801 - val_loss: 1.1424 - val_mae: 0.7681 - val_rmse: 1.0688\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 74s - 5ms/step - loss: 1.1638 - mae: 0.7744 - rmse: 1.0788 - val_loss: 1.1417 - val_mae: 0.7656 - val_rmse: 1.0685\n",
      "Epoch 7/100\n",
      "15000/15000 - 70s - 5ms/step - loss: 1.1624 - mae: 0.7737 - rmse: 1.0781 - val_loss: 1.1439 - val_mae: 0.7680 - val_rmse: 1.0696\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 73s - 5ms/step - loss: 1.1612 - mae: 0.7732 - rmse: 1.0776 - val_loss: 1.1416 - val_mae: 0.7669 - val_rmse: 1.0685\n",
      "Epoch 9/100\n",
      "15000/15000 - 71s - 5ms/step - loss: 1.1611 - mae: 0.7730 - rmse: 1.0775 - val_loss: 1.1421 - val_mae: 0.7693 - val_rmse: 1.0687\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 73s - 5ms/step - loss: 1.1594 - mae: 0.7724 - rmse: 1.0767 - val_loss: 1.1403 - val_mae: 0.7662 - val_rmse: 1.0678\n",
      "Epoch 11/100\n",
      "15000/15000 - 73s - 5ms/step - loss: 1.1588 - mae: 0.7722 - rmse: 1.0765 - val_loss: 1.1406 - val_mae: 0.7649 - val_rmse: 1.0680\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 71s - 5ms/step - loss: 1.1579 - mae: 0.7718 - rmse: 1.0760 - val_loss: 1.1401 - val_mae: 0.7655 - val_rmse: 1.0678\n",
      "Epoch 13/100\n",
      "15000/15000 - 72s - 5ms/step - loss: 1.1561 - mae: 0.7708 - rmse: 1.0752 - val_loss: 1.1417 - val_mae: 0.7660 - val_rmse: 1.0685\n",
      "Epoch 14/100\n",
      "15000/15000 - 74s - 5ms/step - loss: 1.1556 - mae: 0.7706 - rmse: 1.0750 - val_loss: 1.1419 - val_mae: 0.7664 - val_rmse: 1.0686\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 74s - 5ms/step - loss: 1.1564 - mae: 0.7709 - rmse: 1.0754 - val_loss: 1.1400 - val_mae: 0.7642 - val_rmse: 1.0677\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 71s - 5ms/step - loss: 1.1546 - mae: 0.7703 - rmse: 1.0745 - val_loss: 1.1399 - val_mae: 0.7652 - val_rmse: 1.0677\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 65s - 4ms/step - loss: 1.1535 - mae: 0.7697 - rmse: 1.0740 - val_loss: 1.1385 - val_mae: 0.7643 - val_rmse: 1.0670\n",
      "Epoch 18/100\n",
      "15000/15000 - 72s - 5ms/step - loss: 1.1533 - mae: 0.7696 - rmse: 1.0739 - val_loss: 1.1394 - val_mae: 0.7625 - val_rmse: 1.0674\n",
      "Epoch 19/100\n",
      "15000/15000 - 69s - 5ms/step - loss: 1.1537 - mae: 0.7695 - rmse: 1.0741 - val_loss: 1.1392 - val_mae: 0.7639 - val_rmse: 1.0673\n",
      "Epoch 20/100\n",
      "15000/15000 - 70s - 5ms/step - loss: 1.1531 - mae: 0.7694 - rmse: 1.0738 - val_loss: 1.1409 - val_mae: 0.7630 - val_rmse: 1.0681\n",
      "Epoch 21/100\n",
      "15000/15000 - 71s - 5ms/step - loss: 1.1533 - mae: 0.7695 - rmse: 1.0739 - val_loss: 1.1416 - val_mae: 0.7659 - val_rmse: 1.0684\n",
      "Epoch 22/100\n",
      "15000/15000 - 75s - 5ms/step - loss: 1.1532 - mae: 0.7693 - rmse: 1.0739 - val_loss: 1.1429 - val_mae: 0.7657 - val_rmse: 1.0691\n",
      "Epoch 23/100\n",
      "15000/15000 - 78s - 5ms/step - loss: 1.1536 - mae: 0.7698 - rmse: 1.0741 - val_loss: 1.1414 - val_mae: 0.7647 - val_rmse: 1.0684\n",
      "Epoch 24/100\n",
      "15000/15000 - 74s - 5ms/step - loss: 1.1530 - mae: 0.7694 - rmse: 1.0738 - val_loss: 1.1410 - val_mae: 0.7638 - val_rmse: 1.0682\n",
      "Epoch 25/100\n",
      "15000/15000 - 73s - 5ms/step - loss: 1.1523 - mae: 0.7691 - rmse: 1.0735 - val_loss: 1.1421 - val_mae: 0.7643 - val_rmse: 1.0687\n",
      "Epoch 26/100\n",
      "15000/15000 - 77s - 5ms/step - loss: 1.1506 - mae: 0.7683 - rmse: 1.0727 - val_loss: 1.1426 - val_mae: 0.7640 - val_rmse: 1.0689\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 65s - 4ms/step - loss: 1.1506 - mae: 0.7683 - rmse: 1.0727 - val_loss: 1.1375 - val_mae: 0.7611 - val_rmse: 1.0665\n",
      "Epoch 28/100\n",
      "15000/15000 - 70s - 5ms/step - loss: 1.1506 - mae: 0.7686 - rmse: 1.0727 - val_loss: 1.1391 - val_mae: 0.7621 - val_rmse: 1.0673\n",
      "Epoch 29/100\n",
      "15000/15000 - 75s - 5ms/step - loss: 1.1493 - mae: 0.7678 - rmse: 1.0721 - val_loss: 1.1403 - val_mae: 0.7633 - val_rmse: 1.0678\n",
      "Epoch 30/100\n",
      "15000/15000 - 76s - 5ms/step - loss: 1.1496 - mae: 0.7679 - rmse: 1.0722 - val_loss: 1.1402 - val_mae: 0.7629 - val_rmse: 1.0678\n",
      "Epoch 31/100\n",
      "15000/15000 - 75s - 5ms/step - loss: 1.1489 - mae: 0.7675 - rmse: 1.0719 - val_loss: 1.1406 - val_mae: 0.7628 - val_rmse: 1.0680\n",
      "Epoch 32/100\n",
      "15000/15000 - 71s - 5ms/step - loss: 1.1508 - mae: 0.7686 - rmse: 1.0728 - val_loss: 1.1427 - val_mae: 0.7650 - val_rmse: 1.0690\n",
      "Epoch 33/100\n",
      "15000/15000 - 72s - 5ms/step - loss: 1.1511 - mae: 0.7688 - rmse: 1.0729 - val_loss: 1.1400 - val_mae: 0.7624 - val_rmse: 1.0677\n",
      "Epoch 34/100\n",
      "15000/15000 - 77s - 5ms/step - loss: 1.1509 - mae: 0.7685 - rmse: 1.0728 - val_loss: 1.1436 - val_mae: 0.7639 - val_rmse: 1.0694\n",
      "Epoch 35/100\n",
      "15000/15000 - 69s - 5ms/step - loss: 1.1525 - mae: 0.7692 - rmse: 1.0736 - val_loss: 1.1467 - val_mae: 0.7626 - val_rmse: 1.0708\n",
      "Epoch 36/100\n",
      "15000/15000 - 73s - 5ms/step - loss: 1.1552 - mae: 0.7698 - rmse: 1.0748 - val_loss: 1.1428 - val_mae: 0.7599 - val_rmse: 1.0690\n",
      "Epoch 37/100\n",
      "15000/15000 - 74s - 5ms/step - loss: 1.1522 - mae: 0.7682 - rmse: 1.0734 - val_loss: 1.1452 - val_mae: 0.7623 - val_rmse: 1.0702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:53:39.895328: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n",
      "2025-07-15 19:53:39.921430: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 364 bytes spill stores, 364 bytes spill loads\n",
      "\n",
      "2025-07-15 19:53:39.937520: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 56 bytes spill stores, 56 bytes spill loads\n",
      "\n",
      "2025-07-15 19:53:39.988357: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 64 bytes spill stores, 64 bytes spill loads\n",
      "\n",
      "2025-07-15 19:53:39.994059: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 432 bytes spill stores, 432 bytes spill loads\n",
      "\n",
      "2025-07-15 19:53:40.296594: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 784 bytes spill stores, 784 bytes spill loads\n",
      "\n",
      "2025-07-15 19:53:40.416470: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_28', 872 bytes spill stores, 872 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "import os, random, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import all_estimators\n",
    "# scikit-learn has no global seed; we set seeds in train_test_split\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# Load Data\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "# Identify id and target columns\n",
    "id_col = 'id'\n",
    "target_columns = ['Premium Amount']\n",
    "\n",
    "# Combine and encode target\n",
    "df = df_train.copy()\n",
    "y_values = df[target_columns].astype(float).values\n",
    "# Use log1p if all non-negative\n",
    "if np.all(y_values >= 0):\n",
    "    y_enc = np.log1p(y_values)\n",
    "else:\n",
    "    y_enc = y_values\n",
    "\n",
    "# Prepare features\n",
    "drop_cols = [id_col] + target_columns\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "# Testing set\n",
    "X_test = df_test.drop(columns=drop_cols, errors='ignore')\n",
    "test_ids = df_test[id_col]\n",
    "\n",
    "# Feature engineering: drop cols with all missing\n",
    "non_null_cols = X.columns[X.notna().any()].tolist()\n",
    "X = X[non_null_cols]\n",
    "X_test = X_test[non_null_cols]\n",
    "# Identify categorical vs numeric\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# Drop high-cardinality categorical cols\n",
    "high_card = [c for c in categorical_cols if X[c].nunique() > 50]\n",
    "for c in high_card:\n",
    "    X.drop(columns=c, inplace=True)\n",
    "    X_test.drop(columns=c, inplace=True)\n",
    "categorical_cols = [c for c in categorical_cols if c not in high_card]\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "df_train_proc = preprocessor.fit_transform(X)\n",
    "df_test_proc = preprocessor.transform(X_test)\n",
    "n_samples, n_features = df_train_proc.shape\n",
    "\n",
    "# Build model (Keras-Tuner snippet)\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# Define early stopping and checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Preserve input dim\n",
    "n_features = df_train_proc.shape[1]\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        layers = hp.Int('layers', 2, 8)\n",
    "        units = hp.Int('units', 64, 1024)\n",
    "        act = hp.Choice('activation', ['relu'])\n",
    "        drop = hp.Float('dropout', 0.0, 0.5)\n",
    "        opt = hp.Choice('optimizer', ['adam'])\n",
    "        lr = hp.Float('learning_rate', 1e-05, 0.01, sampling='log')\n",
    "\n",
    "        inputs = Input(shape=(n_features,))\n",
    "        x = inputs\n",
    "        for _ in range(layers):\n",
    "            x = Dense(units, activation=act)(x)\n",
    "            x = Dropout(drop)(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        model = Model(inputs, x)\n",
    "        model.compile(optimizer=opt, loss='mean_squared_error', metrics=[RootMeanSquaredError(name='rmse'), MeanAbsoluteError(name='mae')])\n",
    "        return model\n",
    "\n",
    "# Tuner setup\n",
    "bs = 64  # batch size\n",
    "ep = 100  # epochs\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    seed=42,\n",
    "    overwrite=False ,\n",
    "    project_name='bayesian_tuner'\n",
    ")\n",
    "\n",
    "if y_enc is not None:\n",
    "    tuner.search(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "else:\n",
    "    tuner.search(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "\n",
    "model = tuner.hypermodel.build(\n",
    "    tuner.get_best_hyperparameters(1)[0]\n",
    ")\n",
    "\n",
    "# Retrain model with original callbacks and data\n",
    "start_time = time.time()  # Start timing\n",
    "if y_enc is not None:\n",
    "    history = model.fit(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "end_time = time.time()  # End timing\n",
    "duration = end_time - start_time  # Calculate duration\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'training_loss': history.history['loss'][-1],\n",
    "    'validation_loss': history.history['val_loss'][-1],\n",
    "    'training_rmse': history.history['rmse'][-1],\n",
    "    'validation_rmse': history.history['val_rmse'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "raw_preds = model.predict(df_test_proc)\n",
    "# Reverse log\n",
    "final = np.expm1(np.clip(raw_preds, a_min=None, a_max=20))\n",
    "# Ensure 2D\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1,1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688.784352\n"
     ]
    }
   ],
   "source": [
    "print(duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
