{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular Playground Series - May 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-10 13:26:31.656372: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1752153991.673401  966912 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1752153991.678555  966912 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1752153991.692904  966912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752153991.692919  966912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752153991.692921  966912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1752153991.692923  966912 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-07-10 13:26:31.697835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/exouser/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2025-07-10 13:26:47.099177: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 9s - 2ms/step - accuracy: 0.7240 - auc: 0.7982 - loss: 0.5467 - val_accuracy: 0.7826 - val_auc: 0.8616 - val_loss: 0.4728\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 9s - 2ms/step - accuracy: 0.7802 - auc: 0.8542 - loss: 0.4778 - val_accuracy: 0.8218 - val_auc: 0.8967 - val_loss: 0.4164\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8007 - auc: 0.8735 - loss: 0.4492 - val_accuracy: 0.8376 - val_auc: 0.9091 - val_loss: 0.3944\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8097 - auc: 0.8813 - loss: 0.4368 - val_accuracy: 0.8435 - val_auc: 0.9134 - val_loss: 0.3870\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8136 - auc: 0.8850 - loss: 0.4307 - val_accuracy: 0.8456 - val_auc: 0.9147 - val_loss: 0.3844\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8167 - auc: 0.8876 - loss: 0.4265 - val_accuracy: 0.8469 - val_auc: 0.9159 - val_loss: 0.3818\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8193 - auc: 0.8896 - loss: 0.4230 - val_accuracy: 0.8493 - val_auc: 0.9181 - val_loss: 0.3765\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8211 - auc: 0.8917 - loss: 0.4196 - val_accuracy: 0.8508 - val_auc: 0.9193 - val_loss: 0.3735\n",
      "Epoch 9/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8226 - auc: 0.8927 - loss: 0.4179 - val_accuracy: 0.8512 - val_auc: 0.9193 - val_loss: 0.3747\n",
      "Epoch 10/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8230 - auc: 0.8933 - loss: 0.4168 - val_accuracy: 0.8513 - val_auc: 0.9194 - val_loss: 0.3758\n",
      "Epoch 11/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8233 - auc: 0.8936 - loss: 0.4164 - val_accuracy: 0.8508 - val_auc: 0.9193 - val_loss: 0.3736\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 9s - 2ms/step - accuracy: 0.8238 - auc: 0.8944 - loss: 0.4150 - val_accuracy: 0.8527 - val_auc: 0.9205 - val_loss: 0.3719\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 9s - 2ms/step - accuracy: 0.8249 - auc: 0.8950 - loss: 0.4141 - val_accuracy: 0.8529 - val_auc: 0.9209 - val_loss: 0.3719\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8246 - auc: 0.8948 - loss: 0.4144 - val_accuracy: 0.8520 - val_auc: 0.9210 - val_loss: 0.3706\n",
      "Epoch 15/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8252 - auc: 0.8953 - loss: 0.4133 - val_accuracy: 0.8540 - val_auc: 0.9213 - val_loss: 0.3708\n",
      "Epoch 16/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8257 - auc: 0.8955 - loss: 0.4131 - val_accuracy: 0.8533 - val_auc: 0.9214 - val_loss: 0.3713\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8258 - auc: 0.8957 - loss: 0.4128 - val_accuracy: 0.8540 - val_auc: 0.9215 - val_loss: 0.3700\n",
      "Epoch 18/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8258 - auc: 0.8961 - loss: 0.4122 - val_accuracy: 0.8535 - val_auc: 0.9216 - val_loss: 0.3710\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 9s - 2ms/step - accuracy: 0.8257 - auc: 0.8958 - loss: 0.4128 - val_accuracy: 0.8539 - val_auc: 0.9217 - val_loss: 0.3696\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 9s - 2ms/step - accuracy: 0.8273 - auc: 0.8969 - loss: 0.4106 - val_accuracy: 0.8544 - val_auc: 0.9219 - val_loss: 0.3690\n",
      "Epoch 21/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8261 - auc: 0.8965 - loss: 0.4114 - val_accuracy: 0.8556 - val_auc: 0.9224 - val_loss: 0.3701\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8268 - auc: 0.8965 - loss: 0.4114 - val_accuracy: 0.8558 - val_auc: 0.9228 - val_loss: 0.3687\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 9s - 2ms/step - accuracy: 0.8272 - auc: 0.8967 - loss: 0.4109 - val_accuracy: 0.8550 - val_auc: 0.9225 - val_loss: 0.3686\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 2ms/step - accuracy: 0.8274 - auc: 0.8971 - loss: 0.4102 - val_accuracy: 0.8556 - val_auc: 0.9229 - val_loss: 0.3678\n",
      "Epoch 25/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8279 - auc: 0.8972 - loss: 0.4101 - val_accuracy: 0.8558 - val_auc: 0.9230 - val_loss: 0.3679\n",
      "Epoch 26/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8272 - auc: 0.8971 - loss: 0.4106 - val_accuracy: 0.8556 - val_auc: 0.9232 - val_loss: 0.3690\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8276 - auc: 0.8975 - loss: 0.4095 - val_accuracy: 0.8560 - val_auc: 0.9235 - val_loss: 0.3663\n",
      "Epoch 28/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8278 - auc: 0.8977 - loss: 0.4092 - val_accuracy: 0.8563 - val_auc: 0.9234 - val_loss: 0.3686\n",
      "Epoch 29/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8282 - auc: 0.8978 - loss: 0.4090 - val_accuracy: 0.8571 - val_auc: 0.9239 - val_loss: 0.3666\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8284 - auc: 0.8981 - loss: 0.4085 - val_accuracy: 0.8582 - val_auc: 0.9245 - val_loss: 0.3653\n",
      "Epoch 31/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8283 - auc: 0.8981 - loss: 0.4087 - val_accuracy: 0.8569 - val_auc: 0.9241 - val_loss: 0.3664\n",
      "Epoch 32/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8288 - auc: 0.8984 - loss: 0.4079 - val_accuracy: 0.8578 - val_auc: 0.9241 - val_loss: 0.3654\n",
      "Epoch 33/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8283 - auc: 0.8982 - loss: 0.4084 - val_accuracy: 0.8582 - val_auc: 0.9245 - val_loss: 0.3656\n",
      "Epoch 34/100\n",
      "5625/5625 - 8s - 1ms/step - accuracy: 0.8287 - auc: 0.8984 - loss: 0.4080 - val_accuracy: 0.8587 - val_auc: 0.9246 - val_loss: 0.3654\n",
      "Epoch 35/100\n",
      "5625/5625 - 8s - 2ms/step - accuracy: 0.8291 - auc: 0.8987 - loss: 0.4073 - val_accuracy: 0.8591 - val_auc: 0.9249 - val_loss: 0.3657\n",
      "\u001b[1m21875/21875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 569us/step\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('tabular-playground-series-may-2022/train.csv.zip')\n",
    "test_df = pd.read_csv('tabular-playground-series-may-2022/test.csv.zip')\n",
    "sample_sub = pd.read_csv('tabular-playground-series-may-2022/sample_submission.csv.zip')\n",
    "\n",
    "# Infer columns\n",
    "id_col = sample_sub.columns[0]\n",
    "target_col = sample_sub.columns[1]\n",
    "\n",
    "# Prepare dataframes\n",
    "df = train_df.copy()\n",
    "\n",
    "# Encode target\n",
    "e = LabelEncoder()\n",
    "y = e.fit_transform(df[target_col].astype(str))\n",
    "\n",
    "# Separate features and test set\n",
    "X = df.drop(columns=[id_col, target_col], errors='ignore')\n",
    "test_ids = test_df[id_col]\n",
    "X_test = test_df.drop(columns=[id_col, target_col], errors='ignore')\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Feature engineering: drop columns with all missing values\n",
    "X_train = X_train.dropna(axis=1, how='all')\n",
    "X_val = X_val[X_train.columns]\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = [\n",
    "    col for col in X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    if X_train[col].nunique() <= 50\n",
    "]\n",
    "\n",
    "# Build preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Fit and transform data\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# Determine model architecture based on feature size\n",
    "n_features = X_train_proc.shape[1]\n",
    "hidden_units = [min(n_features * 2, 128), min(n_features, 64)]\n",
    "dropout_rate = 0.3\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    Dense(hidden_units[0], activation='relu', input_shape=(n_features,)),\n",
    "    Dropout(dropout_rate),\n",
    "    Dense(hidden_units[1], activation='relu'),\n",
    "    Dropout(dropout_rate),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy', AUC(name='auc')]\n",
    ")\n",
    "\n",
    "# Set up callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train,\n",
    "    validation_data=(X_val_proc, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "duration = time.time() - start_time\n",
    "\n",
    "# Log the final epoch results\n",
    "results = {\n",
    "    'training_accuracy': history.history['accuracy'][-1],\n",
    "    'training_loss': history.history['loss'][-1],\n",
    "    'validation_accuracy': history.history['val_accuracy'][-1],\n",
    "    'validation_loss': history.history['val_loss'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Make predictions on the test set\n",
    "raw_preds = model.predict(X_test_proc)\n",
    "probs = raw_preds.flatten()\n",
    "final_preds = (probs > 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({id_col: test_ids.reset_index(drop=True), target_col: final_preds})\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291.67622900009155\n"
     ]
    }
   ],
   "source": [
    "print(duration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tuner - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 56m 49s]\n",
      "val_loss: 0.28987857699394226\n",
      "\n",
      "Best val_loss So Far: 0.28688332438468933\n",
      "Total elapsed time: 10h 32m 59s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 113s - 5ms/step - accuracy: 0.8097 - auc: 0.8854 - loss: 0.4277 - val_accuracy: 0.8586 - val_auc: 0.9257 - val_loss: 0.3526\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 113s - 5ms/step - accuracy: 0.8542 - auc: 0.9206 - loss: 0.3570 - val_accuracy: 0.8744 - val_auc: 0.9364 - val_loss: 0.3226\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 99s - 4ms/step - accuracy: 0.8668 - auc: 0.9294 - loss: 0.3350 - val_accuracy: 0.8804 - val_auc: 0.9405 - val_loss: 0.3089\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 103s - 5ms/step - accuracy: 0.8733 - auc: 0.9335 - loss: 0.3241 - val_accuracy: 0.8844 - val_auc: 0.9422 - val_loss: 0.3079\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 98s - 4ms/step - accuracy: 0.8761 - auc: 0.9352 - loss: 0.3195 - val_accuracy: 0.8860 - val_auc: 0.9435 - val_loss: 0.3054\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 104s - 5ms/step - accuracy: 0.8785 - auc: 0.9368 - loss: 0.3149 - val_accuracy: 0.8868 - val_auc: 0.9444 - val_loss: 0.3023\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 91s - 4ms/step - accuracy: 0.8802 - auc: 0.9379 - loss: 0.3122 - val_accuracy: 0.8896 - val_auc: 0.9454 - val_loss: 0.2961\n",
      "Epoch 8/100\n",
      "22500/22500 - 96s - 4ms/step - accuracy: 0.8816 - auc: 0.9385 - loss: 0.3101 - val_accuracy: 0.8899 - val_auc: 0.9456 - val_loss: 0.2988\n",
      "Epoch 9/100\n",
      "22500/22500 - 93s - 4ms/step - accuracy: 0.8821 - auc: 0.9391 - loss: 0.3088 - val_accuracy: 0.8894 - val_auc: 0.9453 - val_loss: 0.2989\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 105s - 5ms/step - accuracy: 0.8829 - auc: 0.9394 - loss: 0.3075 - val_accuracy: 0.8910 - val_auc: 0.9464 - val_loss: 0.2939\n",
      "Epoch 11/100\n",
      "22500/22500 - 109s - 5ms/step - accuracy: 0.8836 - auc: 0.9398 - loss: 0.3064 - val_accuracy: 0.8913 - val_auc: 0.9461 - val_loss: 0.2957\n",
      "Epoch 12/100\n",
      "22500/22500 - 87s - 4ms/step - accuracy: 0.8839 - auc: 0.9399 - loss: 0.3064 - val_accuracy: 0.8915 - val_auc: 0.9460 - val_loss: 0.2951\n",
      "Epoch 13/100\n",
      "22500/22500 - 95s - 4ms/step - accuracy: 0.8841 - auc: 0.9400 - loss: 0.3060 - val_accuracy: 0.8918 - val_auc: 0.9466 - val_loss: 0.2991\n",
      "Epoch 14/100\n",
      "22500/22500 - 101s - 4ms/step - accuracy: 0.8846 - auc: 0.9403 - loss: 0.3052 - val_accuracy: 0.8908 - val_auc: 0.9463 - val_loss: 0.2978\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 108s - 5ms/step - accuracy: 0.8848 - auc: 0.9404 - loss: 0.3051 - val_accuracy: 0.8922 - val_auc: 0.9468 - val_loss: 0.2904\n",
      "Epoch 16/100\n",
      "22500/22500 - 99s - 4ms/step - accuracy: 0.8851 - auc: 0.9401 - loss: 0.3053 - val_accuracy: 0.8932 - val_auc: 0.9471 - val_loss: 0.2912\n",
      "Epoch 17/100\n",
      "22500/22500 - 98s - 4ms/step - accuracy: 0.8851 - auc: 0.9406 - loss: 0.3043 - val_accuracy: 0.8909 - val_auc: 0.9461 - val_loss: 0.2948\n",
      "Epoch 18/100\n",
      "22500/22500 - 111s - 5ms/step - accuracy: 0.8853 - auc: 0.9405 - loss: 0.3051 - val_accuracy: 0.8927 - val_auc: 0.9470 - val_loss: 0.2920\n",
      "Epoch 19/100\n",
      "22500/22500 - 103s - 5ms/step - accuracy: 0.8854 - auc: 0.9405 - loss: 0.3043 - val_accuracy: 0.8933 - val_auc: 0.9472 - val_loss: 0.2925\n",
      "Epoch 20/100\n",
      "22500/22500 - 102s - 5ms/step - accuracy: 0.8857 - auc: 0.9408 - loss: 0.3039 - val_accuracy: 0.8915 - val_auc: 0.9472 - val_loss: 0.2942\n",
      "Epoch 21/100\n",
      "22500/22500 - 101s - 4ms/step - accuracy: 0.8859 - auc: 0.9408 - loss: 0.3034 - val_accuracy: 0.8934 - val_auc: 0.9473 - val_loss: 0.2928\n",
      "Epoch 22/100\n",
      "22500/22500 - 110s - 5ms/step - accuracy: 0.8857 - auc: 0.9409 - loss: 0.3041 - val_accuracy: 0.8918 - val_auc: 0.9466 - val_loss: 0.2944\n",
      "Epoch 23/100\n",
      "22500/22500 - 95s - 4ms/step - accuracy: 0.8864 - auc: 0.9409 - loss: 0.3038 - val_accuracy: 0.8908 - val_auc: 0.9470 - val_loss: 0.2944\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 104s - 5ms/step - accuracy: 0.8866 - auc: 0.9411 - loss: 0.3029 - val_accuracy: 0.8944 - val_auc: 0.9481 - val_loss: 0.2899\n",
      "Epoch 25/100\n",
      "22500/22500 - 99s - 4ms/step - accuracy: 0.8865 - auc: 0.9412 - loss: 0.3026 - val_accuracy: 0.8933 - val_auc: 0.9473 - val_loss: 0.2945\n",
      "Epoch 26/100\n",
      "22500/22500 - 104s - 5ms/step - accuracy: 0.8858 - auc: 0.9409 - loss: 0.3035 - val_accuracy: 0.8944 - val_auc: 0.9477 - val_loss: 0.2915\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22500/22500 - 101s - 5ms/step - accuracy: 0.8865 - auc: 0.9411 - loss: 0.3036 - val_accuracy: 0.8941 - val_auc: 0.9477 - val_loss: 0.2881\n",
      "Epoch 28/100\n",
      "22500/22500 - 104s - 5ms/step - accuracy: 0.8867 - auc: 0.9413 - loss: 0.3027 - val_accuracy: 0.8945 - val_auc: 0.9478 - val_loss: 0.2903\n",
      "Epoch 29/100\n",
      "22500/22500 - 94s - 4ms/step - accuracy: 0.8864 - auc: 0.9413 - loss: 0.3029 - val_accuracy: 0.8934 - val_auc: 0.9477 - val_loss: 0.2923\n",
      "Epoch 30/100\n",
      "22500/22500 - 105s - 5ms/step - accuracy: 0.8869 - auc: 0.9413 - loss: 0.3021 - val_accuracy: 0.8941 - val_auc: 0.9485 - val_loss: 0.2925\n",
      "Epoch 31/100\n",
      "22500/22500 - 94s - 4ms/step - accuracy: 0.8873 - auc: 0.9413 - loss: 0.3022 - val_accuracy: 0.8946 - val_auc: 0.9486 - val_loss: 0.2865\n",
      "Epoch 37/100\n",
      "22500/22500 - 96s - 4ms/step - accuracy: 0.8877 - auc: 0.9416 - loss: 0.3022 - val_accuracy: 0.8961 - val_auc: 0.9487 - val_loss: 0.2884\n",
      "Epoch 38/100\n",
      "22500/22500 - 94s - 4ms/step - accuracy: 0.8877 - auc: 0.9414 - loss: 0.3018 - val_accuracy: 0.8949 - val_auc: 0.9484 - val_loss: 0.2875\n",
      "Epoch 39/100\n",
      "22500/22500 - 93s - 4ms/step - accuracy: 0.8874 - auc: 0.9413 - loss: 0.3031 - val_accuracy: 0.8931 - val_auc: 0.9473 - val_loss: 0.2928\n",
      "Epoch 40/100\n",
      "22500/22500 - 97s - 4ms/step - accuracy: 0.8873 - auc: 0.9413 - loss: 0.3021 - val_accuracy: 0.8949 - val_auc: 0.9481 - val_loss: 0.2947\n",
      "Epoch 41/100\n",
      "22500/22500 - 94s - 4ms/step - accuracy: 0.8879 - auc: 0.9415 - loss: 0.3025 - val_accuracy: 0.8934 - val_auc: 0.9474 - val_loss: 0.2929\n",
      "Epoch 42/100\n",
      "22500/22500 - 96s - 4ms/step - accuracy: 0.8875 - auc: 0.9411 - loss: 0.3023 - val_accuracy: 0.8942 - val_auc: 0.9482 - val_loss: 0.2905\n",
      "Epoch 43/100\n",
      "22500/22500 - 102s - 5ms/step - accuracy: 0.8880 - auc: 0.9415 - loss: 0.3012 - val_accuracy: 0.8942 - val_auc: 0.9481 - val_loss: 0.2965\n",
      "Epoch 44/100\n",
      "22500/22500 - 106s - 5ms/step - accuracy: 0.8879 - auc: 0.9414 - loss: 0.3019 - val_accuracy: 0.8945 - val_auc: 0.9478 - val_loss: 0.2875\n",
      "Epoch 45/100\n",
      "22500/22500 - 93s - 4ms/step - accuracy: 0.8875 - auc: 0.9413 - loss: 0.3031 - val_accuracy: 0.8936 - val_auc: 0.9476 - val_loss: 0.2885\n",
      "Epoch 46/100\n",
      "22500/22500 - 98s - 4ms/step - accuracy: 0.8873 - auc: 0.9410 - loss: 0.3030 - val_accuracy: 0.8936 - val_auc: 0.9480 - val_loss: 0.2885\n",
      "\u001b[1m21875/21875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import AUC\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "os.environ['PYTHONHASHSEED'] = '42'\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('train.csv.zip')\n",
    "test_df = pd.read_csv('test.csv.zip')\n",
    "sample_sub = pd.read_csv('sample_submission.csv.zip')\n",
    "\n",
    "# Infer columns\n",
    "id_col = sample_sub.columns[0]\n",
    "target_col = sample_sub.columns[1]\n",
    "\n",
    "# Prepare dataframes\n",
    "df = train_df.copy()\n",
    "\n",
    "# Encode target\n",
    "e = LabelEncoder()\n",
    "y = e.fit_transform(df[target_col].astype(str))\n",
    "\n",
    "# Separate features and test set\n",
    "X = df.drop(columns=[id_col, target_col], errors='ignore')\n",
    "test_ids = test_df[id_col]\n",
    "X_test = test_df.drop(columns=[id_col, target_col], errors='ignore')\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Feature engineering: drop columns with all missing values\n",
    "X_train = X_train.dropna(axis=1, how='all')\n",
    "X_val = X_val[X_train.columns]\n",
    "X_test = X_test[X_train.columns]\n",
    "\n",
    "# Identify numeric and categorical features\n",
    "numeric_cols = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = [\n",
    "    col for col in X_train.select_dtypes(include=['object', 'category']).columns\n",
    "    if X_train[col].nunique() <= 50\n",
    "]\n",
    "\n",
    "# Build preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_cols),\n",
    "    ('cat', categorical_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Fit and transform data\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# Determine model architecture based on feature size\n",
    "n_features = X_train_proc.shape[1]\n",
    "\n",
    "# Early stopping and model checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# HyperModel class\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        layers = hp.Int('layers', 2, 8)\n",
    "        units = hp.Int('units', 64, 1024, 64)\n",
    "        act = hp.Choice('activation', ['relu'])\n",
    "        drop = hp.Float('dropout', 0.0, 0.5, 0.1)\n",
    "        opt = hp.Choice('optimizer', ['adam'])\n",
    "        lr = hp.Float('learning_rate', 1e-5, 0.01, sampling='log')\n",
    "\n",
    "        inputs = Input(shape=(n_features,))\n",
    "        x = inputs\n",
    "        for _ in range(layers):\n",
    "            x = Dense(units, activation=act)(x)\n",
    "            x = Dropout(drop)(x)\n",
    "        x = Dense(1, activation='sigmoid')(x)\n",
    "        model = Model(inputs, x)\n",
    "        model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy', AUC(name='auc')])\n",
    "        return model\n",
    "\n",
    "# Tuner setup\n",
    "bs = 32  # Example batch size\n",
    "ep = 100  # Example epochs\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    seed=42,\n",
    "    overwrite=False,\n",
    "    project_name='bayesian_tuner'\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "if y_val is not None:\n",
    "    tuner.search(\n",
    "        X_train_proc, y_train,\n",
    "        validation_data=(X_val_proc, y_val),\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "else:\n",
    "    tuner.search(\n",
    "        X_train_proc, y_train,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "\n",
    "# Build the best model\n",
    "model = tuner.hypermodel.build(tuner.get_best_hyperparameters(1)[0])\n",
    "\n",
    "start_time = time.time()  # Start timing\n",
    "\n",
    "# Retrain the model with original callbacks and data\n",
    "if y_val is not None:\n",
    "    history = model.fit(\n",
    "        X_train_proc, y_train,\n",
    "        validation_data=(X_val_proc, y_val),\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        X_train_proc, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "duration = time.time() - start_time  # Calculate duration\n",
    "\n",
    "# Log the final epoch results\n",
    "results = {\n",
    "    'training_accuracy': history.history['accuracy'][-1],\n",
    "    'training_loss': history.history['loss'][-1],\n",
    "    'validation_accuracy': history.history['val_accuracy'][-1],\n",
    "    'validation_loss': history.history['val_loss'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Make predictions on the test set\n",
    "raw_preds = model.predict(X_test_proc)\n",
    "probs = raw_preds.flatten()\n",
    "final_preds = (probs > 0.5).astype(int)\n",
    "\n",
    "submission = pd.DataFrame({id_col: test_ids.reset_index(drop=True), target_col: final_preds})\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4625.431574\n"
     ]
    }
   ],
   "source": [
    "print(duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
