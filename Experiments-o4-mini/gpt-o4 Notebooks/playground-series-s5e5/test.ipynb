{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Calorie Expenditure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified the metric from `log1p RMSE` to Raw `RMSE` for both Keras and Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 23s - 2ms/step - loss: 1.1184 - mse_real: 156258.1875 - rmse_real: 155.1820 - val_loss: 0.1161 - val_mse_real: 320.6773 - val_rmse_real: 17.8240\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 21s - 2ms/step - loss: 0.1690 - mse_real: 1536.9480 - rmse_real: 38.3128 - val_loss: 0.0895 - val_mse_real: 348.9626 - val_rmse_real: 18.5622\n",
      "Epoch 3/100\n",
      "9375/9375 - 21s - 2ms/step - loss: 0.1613 - mse_real: 1476.0460 - rmse_real: 37.5259 - val_loss: 0.0996 - val_mse_real: 246.3358 - val_rmse_real: 15.6242\n",
      "Epoch 4/100\n",
      "9375/9375 - 17s - 2ms/step - loss: 0.1597 - mse_real: 1442.6733 - rmse_real: 37.1666 - val_loss: 0.1386 - val_mse_real: 347.7831 - val_rmse_real: 18.5669\n",
      "Epoch 5/100\n",
      "9375/9375 - 17s - 2ms/step - loss: 0.1590 - mse_real: 1432.0992 - rmse_real: 37.0164 - val_loss: 0.2138 - val_mse_real: 353.1501 - val_rmse_real: 18.7299\n",
      "Epoch 6/100\n",
      "9375/9375 - 15s - 2ms/step - loss: 0.1509 - mse_real: 1356.5935 - rmse_real: 36.0223 - val_loss: 0.1937 - val_mse_real: 306.4412 - val_rmse_real: 17.4503\n",
      "Epoch 7/100\n",
      "9375/9375 - 15s - 2ms/step - loss: 0.1516 - mse_real: 1351.7606 - rmse_real: 35.9694 - val_loss: 0.1977 - val_mse_real: 424.3353 - val_rmse_real: 20.5223\n",
      "Epoch 8/100\n",
      "9375/9375 - 15s - 2ms/step - loss: 0.1519 - mse_real: 1346.8545 - rmse_real: 35.9256 - val_loss: 0.1819 - val_mse_real: 288.7579 - val_rmse_real: 16.9362\n",
      "Epoch 9/100\n",
      "9375/9375 - 15s - 2ms/step - loss: 0.1520 - mse_real: 1357.9309 - rmse_real: 36.0562 - val_loss: 0.1888 - val_mse_real: 257.4242 - val_rmse_real: 15.9955\n",
      "Epoch 10/100\n",
      "9375/9375 - 14s - 1ms/step - loss: 0.1512 - mse_real: 1354.8522 - rmse_real: 35.9897 - val_loss: 0.1987 - val_mse_real: 309.6492 - val_rmse_real: 17.5409\n",
      "Epoch 11/100\n",
      "9375/9375 - 15s - 2ms/step - loss: 0.1506 - mse_real: 1345.3895 - rmse_real: 35.8990 - val_loss: 0.1952 - val_mse_real: 325.7027 - val_rmse_real: 17.9782\n",
      "Epoch 12/100\n",
      "9375/9375 - 15s - 2ms/step - loss: 0.1520 - mse_real: 1356.8276 - rmse_real: 36.0317 - val_loss: 0.1868 - val_mse_real: 344.9712 - val_rmse_real: 18.5073\n",
      "\u001b[1m7813/7813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 651us/step\n"
     ]
    }
   ],
   "source": [
    "import random, json, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data\n",
    "sample_sub = pd.read_csv('playground-series-s5e5/sample_submission.csv')\n",
    "id_col = sample_sub.columns[0]\n",
    "target_columns = list(sample_sub.columns[1:])\n",
    "\n",
    "df_train = pd.read_csv('playground-series-s5e5/train.csv')\n",
    "df_test = pd.read_csv('playground-series-s5e5/test.csv')\n",
    "\n",
    "df = df_train.copy()\n",
    "\n",
    "# Target encoding for regression\n",
    "y_values = df[target_columns].astype(float).values\n",
    "# apply log1p since values >= 0\n",
    "y_enc = np.log1p(y_values)\n",
    "\n",
    "# Features\n",
    "X = df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "\n",
    "# Split (use provided test)\n",
    "X_train = X.copy()\n",
    "y_train = y_enc\n",
    "train_ids = df[id_col]\n",
    "test_ids = df_test[id_col]\n",
    "X_val = df_test.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "y_val = None\n",
    "\n",
    "# Feature engineering: drop all-missing\n",
    "all_missing = [c for c in X_train.columns if X_train[c].isna().all()]\n",
    "X_train.drop(columns=all_missing, inplace=True)\n",
    "X_val.drop(columns=all_missing, inplace=True, errors='ignore')\n",
    "# Categorical handling\n",
    "categorical = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "high_card = [c for c in categorical if X_train[c].nunique() > 50]\n",
    "X_train.drop(columns=high_card, inplace=True)\n",
    "X_val.drop(columns=high_card, inplace=True, errors='ignore')\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "# Model architecture guidelines for small dataset\n",
    "n_samples, n_features = X_train_proc.shape\n",
    "units1 = min(n_features * 2, 128)\n",
    "units2 = min(n_features, 64)\n",
    "\n",
    "inputs = Input(shape=(n_features,))\n",
    "x = Dense(units1, activation='relu')(inputs)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(units2, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(len(target_columns), activation='linear')(x)\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[mse_real, rmse_real]\n",
    ")\n",
    "\n",
    "# Callbacks & Training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint('model_best.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "start_time = time.time()\n",
    "if y_val is not None:\n",
    "    history = model.fit(X_train_proc, y_train, validation_data=(X_val_proc, y_val),\n",
    "                        epochs=100, batch_size=64, callbacks=callbacks, verbose=2)\n",
    "else:\n",
    "    history = model.fit(X_train_proc, y_train, validation_split=0.2,\n",
    "                        epochs=100, batch_size=64, callbacks=callbacks, verbose=2)\n",
    "duration = time.time() - start_time\n",
    "\n",
    "# Evaluation & Logging\n",
    "hist = history.history\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('Keras/results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "raw_preds = model.predict(X_val_proc)\n",
    "# inverse log1p\n",
    "final = np.expm1(raw_preds)\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1, 1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('Keras/submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tuner - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 15m 18s]\n",
      "val_loss: 0.010824072174727917\n",
      "\n",
      "Best val_loss So Far: 0.003554456401616335\n",
      "Total elapsed time: 03h 07m 13s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 38s - 4ms/step - loss: 0.0252 - mse_real: 3751.2417 - rmse_real: 8.2843 - val_loss: 0.0053 - val_mse_real: 24.9505 - val_rmse_real: 4.8635\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 34s - 4ms/step - loss: 0.0053 - mse_real: 32.2052 - rmse_real: 5.2252 - val_loss: 0.0049 - val_mse_real: 22.6163 - val_rmse_real: 4.6260\n",
      "Epoch 3/100\n",
      "9375/9375 - 34s - 4ms/step - loss: 0.0048 - mse_real: 26.4636 - rmse_real: 4.7925 - val_loss: 0.0052 - val_mse_real: 40.3812 - val_rmse_real: 6.2617\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 35s - 4ms/step - loss: 0.0046 - mse_real: 24.1529 - rmse_real: 4.5920 - val_loss: 0.0046 - val_mse_real: 22.9312 - val_rmse_real: 4.6823\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 32s - 3ms/step - loss: 0.0045 - mse_real: 22.9233 - rmse_real: 4.4812 - val_loss: 0.0038 - val_mse_real: 16.3908 - val_rmse_real: 3.8658\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 28s - 3ms/step - loss: 0.0044 - mse_real: 22.0416 - rmse_real: 4.3970 - val_loss: 0.0037 - val_mse_real: 15.3377 - val_rmse_real: 3.7387\n",
      "Epoch 7/100\n",
      "9375/9375 - 27s - 3ms/step - loss: 0.0043 - mse_real: 21.3566 - rmse_real: 4.3382 - val_loss: 0.0043 - val_mse_real: 17.2215 - val_rmse_real: 3.9935\n",
      "Epoch 8/100\n",
      "9375/9375 - 33s - 4ms/step - loss: 0.0043 - mse_real: 20.6032 - rmse_real: 4.2697 - val_loss: 0.0043 - val_mse_real: 17.0217 - val_rmse_real: 3.9793\n",
      "Epoch 9/100\n",
      "9375/9375 - 30s - 3ms/step - loss: 0.0042 - mse_real: 20.1837 - rmse_real: 4.2207 - val_loss: 0.0043 - val_mse_real: 17.9855 - val_rmse_real: 4.1026\n",
      "Epoch 10/100\n",
      "9375/9375 - 35s - 4ms/step - loss: 0.0042 - mse_real: 19.7215 - rmse_real: 4.1796 - val_loss: 0.0044 - val_mse_real: 16.7303 - val_rmse_real: 3.9402\n",
      "Epoch 11/100\n",
      "9375/9375 - 38s - 4ms/step - loss: 0.0042 - mse_real: 19.2873 - rmse_real: 4.1379 - val_loss: 0.0042 - val_mse_real: 15.3736 - val_rmse_real: 3.7504\n",
      "Epoch 12/100\n",
      "9375/9375 - 37s - 4ms/step - loss: 0.0041 - mse_real: 18.9336 - rmse_real: 4.1013 - val_loss: 0.0038 - val_mse_real: 14.2372 - val_rmse_real: 3.5929\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 38s - 4ms/step - loss: 0.0041 - mse_real: 18.7374 - rmse_real: 4.0805 - val_loss: 0.0036 - val_mse_real: 14.1114 - val_rmse_real: 3.5641\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 37s - 4ms/step - loss: 0.0040 - mse_real: 18.4523 - rmse_real: 4.0558 - val_loss: 0.0036 - val_mse_real: 14.4003 - val_rmse_real: 3.6006\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 33s - 4ms/step - loss: 0.0040 - mse_real: 18.3934 - rmse_real: 4.0448 - val_loss: 0.0036 - val_mse_real: 13.6440 - val_rmse_real: 3.5009\n",
      "Epoch 16/100\n",
      "9375/9375 - 38s - 4ms/step - loss: 0.0040 - mse_real: 18.1204 - rmse_real: 4.0148 - val_loss: 0.0037 - val_mse_real: 13.8860 - val_rmse_real: 3.5342\n",
      "Epoch 17/100\n",
      "9375/9375 - 38s - 4ms/step - loss: 0.0040 - mse_real: 18.2428 - rmse_real: 4.0091 - val_loss: 0.0036 - val_mse_real: 13.7688 - val_rmse_real: 3.5262\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 38s - 4ms/step - loss: 0.0040 - mse_real: 17.6523 - rmse_real: 3.9735 - val_loss: 0.0036 - val_mse_real: 13.2383 - val_rmse_real: 3.4517\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9375/9375 - 38s - 4ms/step - loss: 0.0040 - mse_real: 17.6502 - rmse_real: 3.9673 - val_loss: 0.0036 - val_mse_real: 13.0555 - val_rmse_real: 3.4282\n",
      "Epoch 20/100\n",
      "9375/9375 - 37s - 4ms/step - loss: 0.0039 - mse_real: 17.4467 - rmse_real: 3.9496 - val_loss: 0.0036 - val_mse_real: 13.3831 - val_rmse_real: 3.4679\n",
      "Epoch 21/100\n",
      "9375/9375 - 38s - 4ms/step - loss: 0.0039 - mse_real: 17.4624 - rmse_real: 3.9430 - val_loss: 0.0036 - val_mse_real: 13.1120 - val_rmse_real: 3.4317\n",
      "Epoch 22/100\n",
      "9375/9375 - 36s - 4ms/step - loss: 0.0039 - mse_real: 17.3227 - rmse_real: 3.9276 - val_loss: 0.0036 - val_mse_real: 13.1681 - val_rmse_real: 3.4414\n",
      "Epoch 23/100\n",
      "9375/9375 - 37s - 4ms/step - loss: 0.0039 - mse_real: 17.2549 - rmse_real: 3.9117 - val_loss: 0.0036 - val_mse_real: 13.3299 - val_rmse_real: 3.4702\n",
      "Epoch 24/100\n",
      "9375/9375 - 37s - 4ms/step - loss: 0.0039 - mse_real: 17.1473 - rmse_real: 3.9090 - val_loss: 0.0036 - val_mse_real: 13.3074 - val_rmse_real: 3.4590\n",
      "Epoch 25/100\n",
      "9375/9375 - 36s - 4ms/step - loss: 0.0039 - mse_real: 17.1491 - rmse_real: 3.9030 - val_loss: 0.0037 - val_mse_real: 13.9380 - val_rmse_real: 3.5577\n",
      "Epoch 26/100\n",
      "9375/9375 - 39s - 4ms/step - loss: 0.0040 - mse_real: 17.1501 - rmse_real: 3.8985 - val_loss: 0.0037 - val_mse_real: 14.1530 - val_rmse_real: 3.5896\n",
      "Epoch 27/100\n",
      "9375/9375 - 39s - 4ms/step - loss: 0.0039 - mse_real: 16.9690 - rmse_real: 3.8826 - val_loss: 0.0038 - val_mse_real: 13.7807 - val_rmse_real: 3.5344\n",
      "Epoch 28/100\n",
      "9375/9375 - 39s - 4ms/step - loss: 0.0039 - mse_real: 16.9930 - rmse_real: 3.8778 - val_loss: 0.0036 - val_mse_real: 13.6295 - val_rmse_real: 3.5137\n",
      "Epoch 29/100\n",
      "9375/9375 - 39s - 4ms/step - loss: 0.0039 - mse_real: 17.3479 - rmse_real: 3.8789 - val_loss: 0.0037 - val_mse_real: 14.3529 - val_rmse_real: 3.6184\n",
      "\u001b[1m7813/7813\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import random, json, time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "import keras_tuner as kt\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data\n",
    "sample_sub = pd.read_csv('playground-series-s5e5/sample_submission.csv')\n",
    "id_col = sample_sub.columns[0]\n",
    "target_columns = list(sample_sub.columns[1:])\n",
    "\n",
    "df_train = pd.read_csv('playground-series-s5e5/train.csv')\n",
    "df_test = pd.read_csv('playground-series-s5e5/test.csv')\n",
    "\n",
    "df = df_train.copy()\n",
    "\n",
    "# Target encoding for regression\n",
    "y_values = df[target_columns].astype(float).values\n",
    "# apply log1p since values >= 0\n",
    "y_enc = np.log1p(y_values)\n",
    "\n",
    "# Features\n",
    "X = df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "\n",
    "# Split (use provided test)\n",
    "X_train = X.copy()\n",
    "y_train = y_enc\n",
    "train_ids = df[id_col]\n",
    "test_ids = df_test[id_col]\n",
    "X_val = df_test.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "y_val = None\n",
    "\n",
    "# Feature engineering: drop all-missing\n",
    "all_missing = [c for c in X_train.columns if X_train[c].isna().all()]\n",
    "X_train.drop(columns=all_missing, inplace=True)\n",
    "X_val.drop(columns=all_missing, inplace=True, errors='ignore')\n",
    "# Categorical handling\n",
    "categorical = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "high_card = [c for c in categorical if X_train[c].nunique() > 50]\n",
    "X_train.drop(columns=high_card, inplace=True)\n",
    "X_val.drop(columns=high_card, inplace=True, errors='ignore')\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "cat_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])\n",
    "\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "# Model architecture guidelines for small dataset\n",
    "n_samples, n_features = X_train_proc.shape\n",
    "units1 = min(n_features * 2, 128)\n",
    "units2 = min(n_features, 64)\n",
    "\n",
    "# Define early stopping and model checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        layers = hp.Int('layers', 2, 8)\n",
    "        units = hp.Int('units', 64, 1024, step=64)\n",
    "        act = hp.Choice('activation', ['relu'])\n",
    "        drop = hp.Float('dropout', 0.0, 0.5, step=0.1)\n",
    "        opt = hp.Choice('optimizer', ['adam'])\n",
    "        lr = hp.Float('learning_rate', 1e-5, 0.01, sampling='log')\n",
    "\n",
    "        inputs = Input(shape=(n_features,))\n",
    "        x = inputs\n",
    "        for _ in range(layers):\n",
    "            x = Dense(units, activation=act)(x)\n",
    "            x = Dropout(drop)(x)\n",
    "        outputs = Dense(len(target_columns), activation='linear')(x)\n",
    "        model = Model(inputs, outputs)\n",
    "        model.compile(optimizer=opt, loss='mean_squared_error', metrics=[mse_real, rmse_real])\n",
    "        return model\n",
    "\n",
    "# Initialize the Bayesian tuner\n",
    "bs = 64  # batch size\n",
    "ep = 100  # epochs\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    seed=42,\n",
    "    overwrite=False,\n",
    "    project_name='bayesian_tuner'\n",
    ")\n",
    "\n",
    "# Search for the best hyperparameters\n",
    "if y_val is not None:\n",
    "    tuner.search(\n",
    "        X_train_proc, y_train,\n",
    "        validation_data=(X_val_proc, y_val),\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "else:\n",
    "    tuner.search(\n",
    "        X_train_proc, y_train,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "\n",
    "# Build the best model\n",
    "model = tuner.hypermodel.build(tuner.get_best_hyperparameters(1)[0])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Retrain the model with the original callbacks and data\n",
    "if y_val is not None:\n",
    "    history = model.fit(\n",
    "        X_train_proc, y_train,\n",
    "        validation_data=(X_val_proc, y_val),\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        X_train_proc, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "\n",
    "duration = time.time() - start_time\n",
    "\n",
    "# Evaluation & Logging\n",
    "hist = history.history\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "raw_preds = model.predict(X_val_proc)\n",
    "# inverse log1p\n",
    "final = np.expm1(raw_preds)\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1, 1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1342.345624\n"
     ]
    }
   ],
   "source": [
    "print(duration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
