{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with an Insurance Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified the metric from `log1p RMSE` to Raw `RMSE` for both Keras and Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - Attempt 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-09 21:42:42.139689: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 31s - 2ms/step - loss: 1.7048 - mse_real: 4287889.0000 - rmse_real: 1247.4364 - val_loss: 1.1586 - val_mse_real: 876568.3125 - val_rmse_real: 927.6188\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 31s - 2ms/step - loss: 1.1823 - mse_real: 890864.3125 - rmse_real: 934.9928 - val_loss: 1.1495 - val_mse_real: 853542.0625 - val_rmse_real: 915.2062\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 30s - 2ms/step - loss: 1.1640 - mse_real: 879367.4375 - rmse_real: 928.8301 - val_loss: 1.1468 - val_mse_real: 858588.0625 - val_rmse_real: 917.9031\n",
      "Epoch 4/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1606 - mse_real: 877315.8750 - rmse_real: 927.7182 - val_loss: 1.1469 - val_mse_real: 860355.8750 - val_rmse_real: 918.8455\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 30s - 2ms/step - loss: 1.1594 - mse_real: 876961.1875 - rmse_real: 927.5292 - val_loss: 1.1440 - val_mse_real: 860644.6250 - val_rmse_real: 918.9793\n",
      "Epoch 6/100\n",
      "15000/15000 - 29s - 2ms/step - loss: 1.1592 - mse_real: 876688.2500 - rmse_real: 927.3759 - val_loss: 1.1451 - val_mse_real: 857753.5625 - val_rmse_real: 917.4307\n",
      "Epoch 7/100\n",
      "15000/15000 - 28s - 2ms/step - loss: 1.1584 - mse_real: 876545.2500 - rmse_real: 927.3005 - val_loss: 1.1451 - val_mse_real: 860740.5625 - val_rmse_real: 919.0282\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 30s - 2ms/step - loss: 1.1580 - mse_real: 876432.1875 - rmse_real: 927.2283 - val_loss: 1.1438 - val_mse_real: 860986.0000 - val_rmse_real: 919.1541\n",
      "Epoch 9/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1578 - mse_real: 876424.1250 - rmse_real: 927.2292 - val_loss: 1.1441 - val_mse_real: 859410.3125 - val_rmse_real: 918.3145\n",
      "Epoch 10/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1575 - mse_real: 876268.8125 - rmse_real: 927.1378 - val_loss: 1.1440 - val_mse_real: 860730.1250 - val_rmse_real: 919.0241\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 29s - 2ms/step - loss: 1.1572 - mse_real: 876436.5000 - rmse_real: 927.2202 - val_loss: 1.1435 - val_mse_real: 865683.6875 - val_rmse_real: 921.6735\n",
      "Epoch 12/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1571 - mse_real: 876152.1250 - rmse_real: 927.0711 - val_loss: 1.1448 - val_mse_real: 858255.6250 - val_rmse_real: 917.7083\n",
      "Epoch 13/100\n",
      "15000/15000 - 41s - 3ms/step - loss: 1.1570 - mse_real: 876197.1250 - rmse_real: 927.1034 - val_loss: 1.1436 - val_mse_real: 862856.0625 - val_rmse_real: 920.1553\n",
      "Epoch 14/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1566 - mse_real: 876125.8125 - rmse_real: 927.0590 - val_loss: 1.1444 - val_mse_real: 860795.0625 - val_rmse_real: 919.0635\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 30s - 2ms/step - loss: 1.1569 - mse_real: 876018.8125 - rmse_real: 927.0026 - val_loss: 1.1430 - val_mse_real: 861053.8125 - val_rmse_real: 919.1776\n",
      "Epoch 16/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1565 - mse_real: 876043.3125 - rmse_real: 927.0031 - val_loss: 1.1440 - val_mse_real: 858249.6250 - val_rmse_real: 917.6908\n",
      "Epoch 17/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1568 - mse_real: 876313.4375 - rmse_real: 927.1526 - val_loss: 1.1437 - val_mse_real: 858215.3125 - val_rmse_real: 917.6813\n",
      "Epoch 18/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1566 - mse_real: 876001.3750 - rmse_real: 926.9979 - val_loss: 1.1436 - val_mse_real: 860405.7500 - val_rmse_real: 918.8242\n",
      "Epoch 19/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1563 - mse_real: 875954.0000 - rmse_real: 926.9533 - val_loss: 1.1433 - val_mse_real: 859081.0625 - val_rmse_real: 918.1259\n",
      "Epoch 20/100\n",
      "15000/15000 - 32s - 2ms/step - loss: 1.1562 - mse_real: 875955.0000 - rmse_real: 926.9717 - val_loss: 1.1436 - val_mse_real: 855561.0625 - val_rmse_real: 916.2500\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 31s - 2ms/step - loss: 1.1561 - mse_real: 875816.0625 - rmse_real: 926.8820 - val_loss: 1.1429 - val_mse_real: 863191.1250 - val_rmse_real: 920.3152\n",
      "Epoch 22/100\n",
      "15000/15000 - 32s - 2ms/step - loss: 1.1560 - mse_real: 876157.0625 - rmse_real: 927.0764 - val_loss: 1.1435 - val_mse_real: 860807.2500 - val_rmse_real: 919.0440\n",
      "Epoch 23/100\n",
      "15000/15000 - 31s - 2ms/step - loss: 1.1562 - mse_real: 876027.5625 - rmse_real: 926.9939 - val_loss: 1.1443 - val_mse_real: 862152.8125 - val_rmse_real: 919.7896\n",
      "Epoch 24/100\n",
      "15000/15000 - 32s - 2ms/step - loss: 1.1562 - mse_real: 876143.6875 - rmse_real: 927.0643 - val_loss: 1.1441 - val_mse_real: 860483.2500 - val_rmse_real: 918.8979\n",
      "Epoch 25/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1558 - mse_real: 876119.5625 - rmse_real: 927.0551 - val_loss: 1.1434 - val_mse_real: 862044.3125 - val_rmse_real: 919.7284\n",
      "Epoch 26/100\n",
      "15000/15000 - 26s - 2ms/step - loss: 1.1557 - mse_real: 876296.0625 - rmse_real: 927.1243 - val_loss: 1.1429 - val_mse_real: 856720.0000 - val_rmse_real: 916.8440\n",
      "Epoch 27/100\n",
      "15000/15000 - 24s - 2ms/step - loss: 1.1557 - mse_real: 876221.6250 - rmse_real: 927.1083 - val_loss: 1.1431 - val_mse_real: 860787.7500 - val_rmse_real: 919.0392\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 22s - 1ms/step - loss: 1.1557 - mse_real: 875998.1250 - rmse_real: 926.9874 - val_loss: 1.1428 - val_mse_real: 861422.1250 - val_rmse_real: 919.3741\n",
      "Epoch 29/100\n",
      "15000/15000 - 21s - 1ms/step - loss: 1.1555 - mse_real: 876012.5625 - rmse_real: 926.9996 - val_loss: 1.1430 - val_mse_real: 859999.4375 - val_rmse_real: 918.6033\n",
      "Epoch 30/100\n",
      "15000/15000 - 22s - 1ms/step - loss: 1.1555 - mse_real: 876289.0000 - rmse_real: 927.1256 - val_loss: 1.1430 - val_mse_real: 855842.6250 - val_rmse_real: 916.3820\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 24s - 2ms/step - loss: 1.1555 - mse_real: 876067.6875 - rmse_real: 927.0204 - val_loss: 1.1425 - val_mse_real: 862858.5000 - val_rmse_real: 920.1399\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 25s - 2ms/step - loss: 1.1556 - mse_real: 876101.2500 - rmse_real: 927.0367 - val_loss: 1.1424 - val_mse_real: 859593.6875 - val_rmse_real: 918.3905\n",
      "Epoch 33/100\n",
      "15000/15000 - 27s - 2ms/step - loss: 1.1554 - mse_real: 876106.5000 - rmse_real: 927.0338 - val_loss: 1.1425 - val_mse_real: 861296.0000 - val_rmse_real: 919.2961\n",
      "Epoch 34/100\n",
      "15000/15000 - 27s - 2ms/step - loss: 1.1551 - mse_real: 875949.7500 - rmse_real: 926.9487 - val_loss: 1.1427 - val_mse_real: 859829.6875 - val_rmse_real: 918.5179\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 24s - 2ms/step - loss: 1.1553 - mse_real: 875999.1875 - rmse_real: 926.9731 - val_loss: 1.1423 - val_mse_real: 861645.5000 - val_rmse_real: 919.4887\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 22s - 1ms/step - loss: 1.1557 - mse_real: 876147.1875 - rmse_real: 927.0469 - val_loss: 1.1421 - val_mse_real: 855427.9375 - val_rmse_real: 916.1270\n",
      "Epoch 37/100\n",
      "15000/15000 - 23s - 2ms/step - loss: 1.1553 - mse_real: 875734.8125 - rmse_real: 926.8301 - val_loss: 1.1423 - val_mse_real: 862999.7500 - val_rmse_real: 920.2047\n",
      "Epoch 38/100\n",
      "15000/15000 - 23s - 2ms/step - loss: 1.1550 - mse_real: 875649.1875 - rmse_real: 926.7905 - val_loss: 1.1430 - val_mse_real: 859685.2500 - val_rmse_real: 918.4477\n",
      "Epoch 39/100\n",
      "15000/15000 - 25s - 2ms/step - loss: 1.1550 - mse_real: 875692.3125 - rmse_real: 926.8151 - val_loss: 1.1435 - val_mse_real: 859122.1875 - val_rmse_real: 918.1373\n",
      "Epoch 40/100\n",
      "15000/15000 - 23s - 2ms/step - loss: 1.1551 - mse_real: 875879.5000 - rmse_real: 926.9092 - val_loss: 1.1440 - val_mse_real: 857177.8125 - val_rmse_real: 917.1180\n",
      "Epoch 41/100\n",
      "15000/15000 - 25s - 2ms/step - loss: 1.1551 - mse_real: 875772.6250 - rmse_real: 926.8583 - val_loss: 1.1426 - val_mse_real: 862425.0625 - val_rmse_real: 919.9142\n",
      "Epoch 42/100\n",
      "15000/15000 - 25s - 2ms/step - loss: 1.1554 - mse_real: 875681.3125 - rmse_real: 926.8227 - val_loss: 1.1432 - val_mse_real: 856991.5000 - val_rmse_real: 916.9980\n",
      "Epoch 43/100\n",
      "15000/15000 - 26s - 2ms/step - loss: 1.1551 - mse_real: 875665.6875 - rmse_real: 926.8100 - val_loss: 1.1435 - val_mse_real: 860837.3125 - val_rmse_real: 919.0713\n",
      "Epoch 44/100\n",
      "15000/15000 - 29s - 2ms/step - loss: 1.1552 - mse_real: 875873.7500 - rmse_real: 926.9275 - val_loss: 1.1429 - val_mse_real: 858827.4375 - val_rmse_real: 917.9921\n",
      "Epoch 45/100\n",
      "15000/15000 - 29s - 2ms/step - loss: 1.1554 - mse_real: 875933.5625 - rmse_real: 926.9329 - val_loss: 1.1437 - val_mse_real: 858171.8750 - val_rmse_real: 917.6510\n",
      "Epoch 46/100\n",
      "15000/15000 - 30s - 2ms/step - loss: 1.1552 - mse_real: 875952.3750 - rmse_real: 926.9465 - val_loss: 1.1434 - val_mse_real: 856421.4375 - val_rmse_real: 916.6923\n",
      "\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 739us/step\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "import os, random, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import all_estimators\n",
    "# scikit-learn has no global seed; we set seeds in train_test_split\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# Load Data\n",
    "df_train = pd.read_csv('playground-series-s4e12/train.csv')\n",
    "df_test = pd.read_csv('playground-series-s4e12/test.csv')\n",
    "# Identify id and target columns\n",
    "id_col = 'id'\n",
    "target_columns = ['Premium Amount']\n",
    "\n",
    "# Combine and encode target\n",
    "df = df_train.copy()\n",
    "y_values = df[target_columns].astype(float).values\n",
    "# Use log1p if all non-negative\n",
    "if np.all(y_values >= 0):\n",
    "    y_enc = np.log1p(y_values)\n",
    "else:\n",
    "    y_enc = y_values\n",
    "\n",
    "# Prepare features\n",
    "drop_cols = [id_col] + target_columns\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "# Testing set\n",
    "X_test = df_test.drop(columns=drop_cols, errors='ignore')\n",
    "test_ids = df_test[id_col]\n",
    "\n",
    "# Feature engineering: drop cols with all missing\n",
    "non_null_cols = X.columns[X.notna().any()].tolist()\n",
    "X = X[non_null_cols]\n",
    "X_test = X_test[non_null_cols]\n",
    "# Identify categorical vs numeric\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# Drop high-cardinality categorical cols\n",
    "high_card = [c for c in categorical_cols if X[c].nunique() > 50]\n",
    "for c in high_card:\n",
    "    X.drop(columns=c, inplace=True)\n",
    "    X_test.drop(columns=c, inplace=True)\n",
    "categorical_cols = [c for c in categorical_cols if c not in high_card]\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "df_train_proc = preprocessor.fit_transform(X)\n",
    "df_test_proc = preprocessor.transform(X_test)\n",
    "n_samples, n_features = df_train_proc.shape\n",
    "\n",
    "# Build model (small dataset branch)\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "hidden_units = [min(n_features*2, 128), min(n_features, 64)]\n",
    "model = models.Sequential()\n",
    "for units in hidden_units:\n",
    "    model.add(layers.Dense(units, activation='relu'))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[rmse_real, mse_real]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "# Training\n",
    "time_start = time.time()\n",
    "history = model.fit(\n",
    "    df_train_proc, y_enc,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "time_duration = time.time() - time_start\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('Keras/results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "raw_preds = model.predict(df_test_proc)\n",
    "# Reverse log\n",
    "final = np.expm1(np.clip(raw_preds, a_min=None, a_max=20))\n",
    "# Ensure 2D\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1,1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('Keras/submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras Tuner - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 21m 06s]\n",
      "val_loss: 1.1446022987365723\n",
      "\n",
      "Best val_loss So Far: 1.1321594715118408\n",
      "Total elapsed time: 04h 26m 48s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-15 19:10:00.840071: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 496 bytes spill stores, 496 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:00.889840: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:00.943026: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 152 bytes spill stores, 152 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.026897: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 240 bytes spill stores, 240 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.084641: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42_0', 40 bytes spill stores, 40 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.105375: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 420 bytes spill stores, 420 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.317834: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 988 bytes spill stores, 988 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.352327: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 1984 bytes spill stores, 1996 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.622911: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 2744 bytes spill stores, 2492 bytes spill loads\n",
      "\n",
      "2025-07-15 19:10:01.707984: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_42', 3160 bytes spill stores, 2988 bytes spill loads\n",
      "\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 108s - 7ms/step - loss: 1.2427 - mse_real: 1356109.5000 - rmse_real: 951.8457 - val_loss: 1.1511 - val_mse_real: 877535.3125 - val_rmse_real: 928.0486\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 93s - 6ms/step - loss: 1.1817 - mse_real: 885380.5625 - rmse_real: 931.9096 - val_loss: 1.1477 - val_mse_real: 879056.4375 - val_rmse_real: 928.8105\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 79s - 5ms/step - loss: 1.1733 - mse_real: 881220.3750 - rmse_real: 929.7810 - val_loss: 1.1474 - val_mse_real: 867389.0000 - val_rmse_real: 922.6240\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 106s - 7ms/step - loss: 1.1700 - mse_real: 879991.2500 - rmse_real: 929.1287 - val_loss: 1.1453 - val_mse_real: 872620.4375 - val_rmse_real: 925.4164\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 124s - 8ms/step - loss: 1.1668 - mse_real: 879020.5000 - rmse_real: 928.5814 - val_loss: 1.1426 - val_mse_real: 867315.2500 - val_rmse_real: 922.5851\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 116s - 8ms/step - loss: 1.1637 - mse_real: 877490.4375 - rmse_real: 927.7740 - val_loss: 1.1417 - val_mse_real: 869388.5000 - val_rmse_real: 923.6783\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 119s - 8ms/step - loss: 1.1616 - mse_real: 876231.2500 - rmse_real: 927.1092 - val_loss: 1.1409 - val_mse_real: 867519.0625 - val_rmse_real: 922.6592\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 130s - 9ms/step - loss: 1.1607 - mse_real: 877101.1875 - rmse_real: 927.1332 - val_loss: 1.1408 - val_mse_real: 863777.4375 - val_rmse_real: 920.6606\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 - 118s - 8ms/step - loss: 1.1595 - mse_real: 875484.9375 - rmse_real: 926.7154 - val_loss: 1.1398 - val_mse_real: 866993.8125 - val_rmse_real: 922.3813\n",
      "Epoch 10/100\n",
      "15000/15000 - 116s - 8ms/step - loss: 1.1588 - mse_real: 875258.5625 - rmse_real: 926.5756 - val_loss: 1.1402 - val_mse_real: 866803.3750 - val_rmse_real: 922.2396\n",
      "Epoch 11/100\n",
      "15000/15000 - 99s - 7ms/step - loss: 1.1575 - mse_real: 874781.1250 - rmse_real: 926.3040 - val_loss: 1.1444 - val_mse_real: 858642.6875 - val_rmse_real: 917.9684\n",
      "Epoch 12/100\n",
      "15000/15000 - 95s - 6ms/step - loss: 1.1567 - mse_real: 874309.6875 - rmse_real: 926.0527 - val_loss: 1.1415 - val_mse_real: 861942.0625 - val_rmse_real: 919.7040\n",
      "Epoch 13/100\n",
      "15000/15000 - 96s - 6ms/step - loss: 1.1573 - mse_real: 269315424.0000 - rmse_real: 1059.4489 - val_loss: 1.1429 - val_mse_real: 859218.0000 - val_rmse_real: 918.2705\n",
      "Epoch 14/100\n",
      "15000/15000 - 96s - 6ms/step - loss: 1.1564 - mse_real: 881126.5625 - rmse_real: 926.5775 - val_loss: 1.1421 - val_mse_real: 866017.1875 - val_rmse_real: 921.8822\n",
      "Epoch 15/100\n",
      "15000/15000 - 93s - 6ms/step - loss: 1.1560 - mse_real: 1044615.4375 - rmse_real: 929.0928 - val_loss: 1.1419 - val_mse_real: 861039.8750 - val_rmse_real: 919.2052\n",
      "Epoch 16/100\n",
      "15000/15000 - 92s - 6ms/step - loss: 1.1548 - mse_real: 872968.0000 - rmse_real: 925.3558 - val_loss: 1.1409 - val_mse_real: 861860.8750 - val_rmse_real: 919.6353\n",
      "Epoch 17/100\n",
      "15000/15000 - 93s - 6ms/step - loss: 1.1540 - mse_real: 9833435136.0000 - rmse_real: 1734.8352 - val_loss: 1.1410 - val_mse_real: 860404.3750 - val_rmse_real: 918.8170\n",
      "Epoch 18/100\n",
      "15000/15000 - 99s - 7ms/step - loss: 1.1543 - mse_real: 872798.4375 - rmse_real: 925.2746 - val_loss: 1.1418 - val_mse_real: 858314.8750 - val_rmse_real: 917.7397\n",
      "Epoch 19/100\n",
      "15000/15000 - 101s - 7ms/step - loss: 1.1528 - mse_real: 872166.0000 - rmse_real: 924.9261 - val_loss: 1.1448 - val_mse_real: 858683.0625 - val_rmse_real: 917.9431\n",
      "\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "import os, random, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import all_estimators\n",
    "# scikit-learn has no global seed; we set seeds in train_test_split\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# Load Data\n",
    "df_train = pd.read_csv('playground-series-s4e12/train.csv')\n",
    "df_test = pd.read_csv('playground-series-s4e12/test.csv')\n",
    "# Identify id and target columns\n",
    "id_col = 'id'\n",
    "target_columns = ['Premium Amount']\n",
    "\n",
    "# Combine and encode target\n",
    "df = df_train.copy()\n",
    "y_values = df[target_columns].astype(float).values\n",
    "# Use log1p if all non-negative\n",
    "if np.all(y_values >= 0):\n",
    "    y_enc = np.log1p(y_values)\n",
    "else:\n",
    "    y_enc = y_values\n",
    "\n",
    "# Prepare features\n",
    "drop_cols = [id_col] + target_columns\n",
    "X = df.drop(columns=drop_cols, errors='ignore')\n",
    "# Testing set\n",
    "X_test = df_test.drop(columns=drop_cols, errors='ignore')\n",
    "test_ids = df_test[id_col]\n",
    "\n",
    "# Feature engineering: drop cols with all missing\n",
    "non_null_cols = X.columns[X.notna().any()].tolist()\n",
    "X = X[non_null_cols]\n",
    "X_test = X_test[non_null_cols]\n",
    "# Identify categorical vs numeric\n",
    "categorical_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "# Drop high-cardinality categorical cols\n",
    "high_card = [c for c in categorical_cols if X[c].nunique() > 50]\n",
    "for c in high_card:\n",
    "    X.drop(columns=c, inplace=True)\n",
    "    X_test.drop(columns=c, inplace=True)\n",
    "categorical_cols = [c for c in categorical_cols if c not in high_card]\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Preprocessing pipeline\n",
    "numeric_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Fit and transform\n",
    "df_train_proc = preprocessor.fit_transform(X)\n",
    "df_test_proc = preprocessor.transform(X_test)\n",
    "n_samples, n_features = df_train_proc.shape\n",
    "\n",
    "# Build model (Keras-Tuner snippet)\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# Define early stopping and checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Preserve input dim\n",
    "n_features = df_train_proc.shape[1]\n",
    "\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        layers = hp.Int('layers', 2, 8)\n",
    "        units = hp.Int('units', 64, 1024)\n",
    "        act = hp.Choice('activation', ['relu'])\n",
    "        drop = hp.Float('dropout', 0.0, 0.5)\n",
    "        opt = hp.Choice('optimizer', ['adam'])\n",
    "        lr = hp.Float('learning_rate', 1e-05, 0.01, sampling='log')\n",
    "\n",
    "        inputs = Input(shape=(n_features,))\n",
    "        x = inputs\n",
    "        for _ in range(layers):\n",
    "            x = Dense(units, activation=act)(x)\n",
    "            x = Dropout(drop)(x)\n",
    "        x = Dense(1, activation='linear')(x)\n",
    "        model = Model(inputs, x)\n",
    "        model.compile(optimizer=opt, loss='mean_squared_error', metrics=[rmse_real, mse_real])\n",
    "        return model\n",
    "\n",
    "# Tuner setup\n",
    "bs = 64  # batch size\n",
    "ep = 100  # epochs\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    seed=42,\n",
    "    overwrite=False,\n",
    "    project_name='bayesian_tuner'\n",
    ")\n",
    "\n",
    "if y_enc is not None:\n",
    "    tuner.search(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "else:\n",
    "    tuner.search(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "\n",
    "model = tuner.hypermodel.build(\n",
    "    tuner.get_best_hyperparameters(1)[0]\n",
    ")\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "# Retrain model with original callbacks and data\n",
    "if y_enc is not None:\n",
    "    history = model.fit(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        df_train_proc, y_enc,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "time_duration = time.time() - time_start\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "raw_preds = model.predict(df_test_proc)\n",
    "# Reverse log\n",
    "final = np.expm1(np.clip(raw_preds, a_min=None, a_max=20))\n",
    "# Ensure 2D\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1,1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688.784352\n"
     ]
    }
   ],
   "source": [
    "print(time_duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
