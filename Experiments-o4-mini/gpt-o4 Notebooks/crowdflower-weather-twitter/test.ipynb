{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partly Sunny with a Chance of Hashtags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified the metric from `log1p RMSE` to Raw `RMSE` for both Keras and Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exouser/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.69315, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 - 2s - 4ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.69315\n",
      "488/488 - 1s - 2ms/step - loss: 0.6931 - mse_real: 0.4269 - rmse_real: 0.6533 - val_loss: 0.6931 - val_mse_real: 0.4261 - val_rmse_real: 0.6528\n",
      "Epoch 11: early stopping\n",
      "Restoring model weights from the end of the best epoch: 1.\n",
      "\u001b[1m1318/1318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 640us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('crowdflower-weather-twitter/train.csv.zip')\n",
    "test_df = pd.read_csv('crowdflower-weather-twitter/test.csv.zip')\n",
    "sub_example = pd.read_csv('crowdflower-weather-twitter/sampleSubmission.csv.zip', nrows=1)\n",
    "id_col = sub_example.columns[0]\n",
    "target_columns = list(sub_example.columns[1:])\n",
    "\n",
    "# Prepare X and y\n",
    "# Drop rows/columns with all missing in train\n",
    "train_df = train_df.dropna(axis=1, how='all')\n",
    "\n",
    "y = train_df[target_columns].values\n",
    "X = train_df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "X = X.dropna(axis=1, how='all')\n",
    "\n",
    "# Prepare test features and ids\n",
    "X_test = test_df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "test_ids = test_df[id_col].reset_index(drop=True)\n",
    "\n",
    "# Feature engineering: detect numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype=='object' and X[c].nunique() <= 50]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "X_proc = preprocessor.fit_transform(X)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# Model architecture decision\n",
    "d, m = X_proc.shape[1], len(target_columns)\n",
    "n_samples = X_proc.shape[0]\n",
    "\n",
    "model = Sequential()\n",
    "if n_samples < 10000 or d < 100:\n",
    "    # small dataset\n",
    "    units1 = min(d * 2, 128)\n",
    "    units2 = min(d, 64)\n",
    "    model.add(Dense(units1, activation='relu', input_shape=(d,)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(units2, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "else:\n",
    "    # larger dataset (unused here but provided)\n",
    "    layers = [min(d * i, 1024) for i in (2, 1, 0.5, 0.25)]\n",
    "    layers = [u for u in layers if u >= 16]\n",
    "    model.add(Dense(layers[0], activation='relu', input_shape=(d,)))\n",
    "    for u in layers[1:]:\n",
    "        model.add(Dense(u, activation='relu'))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(Dropout(0.4))\n",
    "\n",
    "# Output layer for multi-label classification\n",
    "model.add(Dense(m, activation='sigmoid'))\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[mse_real, rmse_real]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', verbose=1)\n",
    "]\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_proc, y,\n",
    "    validation_split=0.2,\n",
    "    epochs=100,\n",
    "    batch_size=128,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "duration = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('Keras/results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Predictions & Submission\n",
    "raw_preds = model.predict(X_test_proc)\n",
    "final = (raw_preds > 0.5).astype(int)\n",
    "\n",
    "import pandas as pd\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids)\n",
    "submission.to_csv('Keras/submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tuner - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 03m 06s]\n",
      "val_loss: 0.3097052574157715\n",
      "\n",
      "Best val_loss So Far: 0.3097052574157715\n",
      "Total elapsed time: 00h 32m 10s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 12s - 13ms/step - loss: 0.5541 - mse_real: 0.2993 - rmse_real: 0.5446 - val_loss: 0.4544 - val_mse_real: 0.2218 - val_rmse_real: 0.4709\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 10ms/step - loss: 0.4044 - mse_real: 0.1974 - rmse_real: 0.4440 - val_loss: 0.3681 - val_mse_real: 0.1817 - val_rmse_real: 0.4261\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 11s - 11ms/step - loss: 0.3492 - mse_real: 0.1778 - rmse_real: 0.4215 - val_loss: 0.3349 - val_mse_real: 0.1739 - val_rmse_real: 0.4169\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 10ms/step - loss: 0.3273 - mse_real: 0.1739 - rmse_real: 0.4169 - val_loss: 0.3212 - val_mse_real: 0.1724 - val_rmse_real: 0.4151\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 10ms/step - loss: 0.3179 - mse_real: 0.1732 - rmse_real: 0.4160 - val_loss: 0.3152 - val_mse_real: 0.1721 - val_rmse_real: 0.4147\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 11s - 11ms/step - loss: 0.3137 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3124 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 11ms/step - loss: 0.3117 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3110 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 10ms/step - loss: 0.3108 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3103 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 11s - 11ms/step - loss: 0.3103 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3100 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 11ms/step - loss: 0.3100 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3098 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 11s - 11ms/step - loss: 0.3099 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3098 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 10ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 10ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 8s - 9ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 9s - 9ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 11s - 11ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 10s - 11ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 12s - 12ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 9s - 9ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 20/100\n",
      "975/975 - 9s - 10ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 9s - 10ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 - 12s - 12ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 23/100\n",
      "975/975 - 9s - 9ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 24/100\n",
      "975/975 - 8s - 9ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 25/100\n",
      "975/975 - 8s - 9ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 26/100\n",
      "975/975 - 9s - 9ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 27/100\n",
      "975/975 - 10s - 11ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 28/100\n",
      "975/975 - 10s - 11ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 29/100\n",
      "975/975 - 10s - 10ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 30/100\n",
      "975/975 - 13s - 13ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 31/100\n",
      "975/975 - 12s - 12ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "Epoch 32/100\n",
      "975/975 - 13s - 13ms/step - loss: 0.3098 - mse_real: 0.1730 - rmse_real: 0.4158 - val_loss: 0.3097 - val_mse_real: 0.1720 - val_rmse_real: 0.4146\n",
      "\u001b[1m1318/1318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load data\n",
    "train_df = pd.read_csv('crowdflower-weather-twitter/train.csv.zip')\n",
    "test_df = pd.read_csv('crowdflower-weather-twitter/test.csv.zip')\n",
    "sub_example = pd.read_csv('crowdflower-weather-twitter/sampleSubmission.csv.zip', nrows=1)\n",
    "id_col = sub_example.columns[0]\n",
    "target_columns = list(sub_example.columns[1:])\n",
    "\n",
    "# Prepare X and y\n",
    "# Drop rows/columns with all missing in train\n",
    "train_df = train_df.dropna(axis=1, how='all')\n",
    "\n",
    "y = train_df[target_columns].values\n",
    "X = train_df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "X = X.dropna(axis=1, how='all')\n",
    "\n",
    "# Prepare test features and ids\n",
    "X_test = test_df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "test_ids = test_df[id_col].reset_index(drop=True)\n",
    "\n",
    "# Feature engineering: detect numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = [c for c in X.columns if X[c].dtype=='object' and X[c].nunique() <= 50]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, numeric_cols),\n",
    "    ('cat', cat_pipeline, categorical_cols)\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "X_proc = preprocessor.fit_transform(X)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "\n",
    "# Model architecture decision\n",
    "d, m = X_proc.shape[1], len(target_columns)\n",
    "n_samples = X_proc.shape[0]\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# Define early stopping and checkpoint\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Input dimension\n",
    "n_features = X_proc.shape[1]\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "# HyperModel\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        layers = hp.Int('layers', 2, 8)\n",
    "        units = hp.Int('units', 64, 1024, 64)\n",
    "        act = hp.Choice('activation', ['relu'])\n",
    "        drop = hp.Float('dropout', 0.0, 0.5)\n",
    "        opt = hp.Choice('optimizer', ['adam'])\n",
    "        lr = hp.Float('learning_rate', 1e-5, 0.01, sampling='log')\n",
    "\n",
    "        inputs = Input(shape=(n_features,))\n",
    "        x = inputs\n",
    "        for _ in range(layers):\n",
    "            x = Dense(units, activation=act)(x)\n",
    "            x = Dropout(drop)(x)\n",
    "        x = Dense(m, activation='sigmoid')(x)  # Output layer for multi-label classification\n",
    "        model = Model(inputs, x)\n",
    "        model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[mse_real, rmse_real])\n",
    "        return model\n",
    "\n",
    "# Tuner\n",
    "bs = 64  # batch size\n",
    "ep = 50  # epochs\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    seed=42,\n",
    "    overwrite=False,\n",
    "    project_name='bayesian_tuner'\n",
    ")\n",
    "\n",
    "if y is not None:\n",
    "    tuner.search(\n",
    "        X_proc, y,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "else:\n",
    "    tuner.search(\n",
    "        X_proc, y,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "\n",
    "model = tuner.hypermodel.build(\n",
    "    tuner.get_best_hyperparameters(1)[0]\n",
    ")\n",
    "start_time = time.time()\n",
    "# Retrain model with original callbacks and data\n",
    "if y is not None:\n",
    "    history = model.fit(\n",
    "        X_proc, y,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        X_proc, y,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "duration = time.time() - start_time\n",
    "\n",
    "# Save results\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Predictions & Submission\n",
    "raw_preds = model.predict(X_test_proc)\n",
    "final = (raw_preds > 0.5).astype(int)\n",
    "\n",
    "import pandas as pd\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids)\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "323.957296\n"
     ]
    }
   ],
   "source": [
    "print(duration)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
