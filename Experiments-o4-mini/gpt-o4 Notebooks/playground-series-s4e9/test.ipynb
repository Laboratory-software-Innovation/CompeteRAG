{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression of Used Car Prices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modified the metric from `log1p RMSE` to Raw `RMSE` for both Keras and Keras Tuner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/exouser/.local/lib/python3.12/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 0.75041, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 4s - 2ms/step - loss: 12.3391 - mse_real: 71144010940416.0000 - rmse_real: 3462145.2500 - val_loss: 0.7504 - val_mse_real: 5853377024.0000 - val_rmse_real: 57668.3789\n",
      "Epoch 2/100\n",
      "\n",
      "Epoch 2: val_loss improved from 0.75041 to 0.54282, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 4s - 2ms/step - loss: 5.8454 - mse_real: 1114419625984.0000 - rmse_real: 657254.7500 - val_loss: 0.5428 - val_mse_real: 5615367168.0000 - val_rmse_real: 55212.7969\n",
      "Epoch 3/100\n",
      "\n",
      "Epoch 3: val_loss improved from 0.54282 to 0.45569, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 4s - 2ms/step - loss: 3.5368 - mse_real: 43524018176.0000 - rmse_real: 185697.3125 - val_loss: 0.4557 - val_mse_real: 5485157888.0000 - val_rmse_real: 53866.5781\n",
      "Epoch 4/100\n",
      "\n",
      "Epoch 4: val_loss improved from 0.45569 to 0.37745, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 3s - 1ms/step - loss: 2.1124 - mse_real: 13807226880.0000 - rmse_real: 103741.1250 - val_loss: 0.3774 - val_mse_real: 5388912640.0000 - val_rmse_real: 52784.5508\n",
      "Epoch 5/100\n",
      "\n",
      "Epoch 5: val_loss improved from 0.37745 to 0.33741, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 3s - 1ms/step - loss: 1.1412 - mse_real: 7928892928.0000 - rmse_real: 71278.3125 - val_loss: 0.3374 - val_mse_real: 5271377408.0000 - val_rmse_real: 51529.6211\n",
      "Epoch 6/100\n",
      "\n",
      "Epoch 6: val_loss improved from 0.33741 to 0.31136, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 3s - 1ms/step - loss: 0.5927 - mse_real: 6472240640.0000 - rmse_real: 58241.6016 - val_loss: 0.3114 - val_mse_real: 5149201920.0000 - val_rmse_real: 50217.9570\n",
      "Epoch 7/100\n",
      "\n",
      "Epoch 7: val_loss improved from 0.31136 to 0.30957, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 3s - 1ms/step - loss: 0.3941 - mse_real: 6081110016.0000 - rmse_real: 53577.2578 - val_loss: 0.3096 - val_mse_real: 5095639552.0000 - val_rmse_real: 49656.1680\n",
      "Epoch 8/100\n",
      "\n",
      "Epoch 8: val_loss improved from 0.30957 to 0.30434, saving model to best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2357/2357 - 3s - 1ms/step - loss: 0.3574 - mse_real: 5993613312.0000 - rmse_real: 52478.4844 - val_loss: 0.3043 - val_mse_real: 5073657856.0000 - val_rmse_real: 49443.0898\n",
      "Epoch 9/100\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3496 - mse_real: 5966213120.0000 - rmse_real: 52144.4258 - val_loss: 0.3079 - val_mse_real: 5053559296.0000 - val_rmse_real: 49250.4297\n",
      "Epoch 10/100\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3470 - mse_real: 5961902592.0000 - rmse_real: 52032.2461 - val_loss: 0.3114 - val_mse_real: 5075383808.0000 - val_rmse_real: 49463.0547\n",
      "Epoch 11/100\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3462 - mse_real: 5953558528.0000 - rmse_real: 51985.5664 - val_loss: 0.3116 - val_mse_real: 5067457024.0000 - val_rmse_real: 49389.9883\n",
      "Epoch 12/100\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3461 - mse_real: 5956694016.0000 - rmse_real: 51998.0859 - val_loss: 0.3082 - val_mse_real: 5075128832.0000 - val_rmse_real: 49466.1758\n",
      "Epoch 13/100\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3464 - mse_real: 5959614976.0000 - rmse_real: 52054.8047 - val_loss: 0.3096 - val_mse_real: 5056461312.0000 - val_rmse_real: 49279.2930\n",
      "Epoch 14/100\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3468 - mse_real: 5965970944.0000 - rmse_real: 52093.9883 - val_loss: 0.3047 - val_mse_real: 5046300160.0000 - val_rmse_real: 49182.4570\n",
      "Epoch 15/100\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3465 - mse_real: 5957222400.0000 - rmse_real: 52031.0898 - val_loss: 0.3063 - val_mse_real: 5037915648.0000 - val_rmse_real: 49102.6211\n",
      "Epoch 16/100\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3470 - mse_real: 5964160000.0000 - rmse_real: 52070.0312 - val_loss: 0.3089 - val_mse_real: 5050414080.0000 - val_rmse_real: 49226.8984\n",
      "Epoch 17/100\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3450 - mse_real: 5948703744.0000 - rmse_real: 51968.2188 - val_loss: 0.3066 - val_mse_real: 5048307200.0000 - val_rmse_real: 49203.9141\n",
      "Epoch 18/100\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.30434\n",
      "2357/2357 - 3s - 1ms/step - loss: 0.3452 - mse_real: 5956081664.0000 - rmse_real: 51990.7344 - val_loss: 0.3089 - val_mse_real: 5063790080.0000 - val_rmse_real: 49349.0938\n",
      "Epoch 18: early stopping\n",
      "Restoring model weights from the end of the best epoch: 8.\n",
      "\u001b[1m3928/3928\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 563us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Reproducibility\n",
    "import os, random, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Data Loading\n",
    "train_df = pd.read_csv('playground-series-s4e9/train.csv.zip')\n",
    "test_df = pd.read_csv('playground-series-s4e9/test.csv.zip')\n",
    "sample_sub = pd.read_csv('playground-series-s4e9/sample_submission.csv.zip', nrows=1)\n",
    "\n",
    "# Infer ID and target columns\n",
    "cols = list(sample_sub.columns)\n",
    "id_col = cols[0]\n",
    "target_columns = cols[1:]\n",
    "\n",
    "# Combine training data\n",
    "df = train_df.copy()\n",
    "\n",
    "# Target encoding for continuous regression\n",
    "y_values = df[target_columns].astype(float).values\n",
    "if np.all(y_values >= 0):\n",
    "    y_enc = np.log1p(y_values)\n",
    "else:\n",
    "    y_enc = y_values\n",
    "\n",
    "# Features\n",
    "X = df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Optional: drop ID from features\n",
    "for df_ in (X_train, X_val):\n",
    "    if id_col in df_.columns:\n",
    "        df_.drop(columns=[id_col], inplace=True)\n",
    "\n",
    "# Drop all-missing columns\n",
    "all_missing = [c for c in X_train.columns if X_train[c].isna().all()]\n",
    "X_train.drop(columns=all_missing, inplace=True)\n",
    "X_val.drop(columns=all_missing, inplace=True)\n",
    "\n",
    "# Feature types\n",
    "numeric_features = X_train.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_features = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "low_cardinality = [c for c in cat_features if X_train[c].nunique() <= 50]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, low_cardinality)\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "# Model architecture determination\n",
    "n_samples, n_features = X_train_proc.shape\n",
    "n_targets = y_train.shape[1] if y_train.ndim > 1 else 1\n",
    "\n",
    "if n_samples < 10000 or n_features < 100:\n",
    "    layer_sizes = [min(n_features*2, 128), min(n_features, 64)]\n",
    "    use_bn = False\n",
    "    drop_rates = [0.3, 0.3]\n",
    "else:\n",
    "    sizes = [n_features * i for i in (2, 1, 0.5, 0.25)]\n",
    "    layer_sizes = [int(min(s, 1024)) for s in sizes if min(s, 1024) >= 16]\n",
    "    use_bn = True\n",
    "    drop_rates = [0.4] * len(layer_sizes)\n",
    "\n",
    "# Build model\n",
    "model = Sequential()\n",
    "for idx, size in enumerate(layer_sizes):\n",
    "    if idx == 0:\n",
    "        model.add(Dense(size, activation='relu', input_dim=n_features))\n",
    "    else:\n",
    "        model.add(Dense(size, activation='relu'))\n",
    "    if use_bn:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(Dropout(drop_rates[idx]))\n",
    "model.add(Dense(n_targets, activation='linear'))\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "# Compile\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='mean_squared_error',\n",
    "    metrics=[rmse_real,mse_real]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n",
    "    ModelCheckpoint('best_model.h5', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# Training\n",
    "start_time = time.time()\n",
    "history = model.fit(\n",
    "    X_train_proc, y_train,\n",
    "    validation_data=(X_val_proc, y_val),\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=2\n",
    ")\n",
    "duration = time.time() - start_time\n",
    "\n",
    "# Logging results\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "X_test = test_df.copy()\n",
    "if id_col in X_test.columns:\n",
    "    test_ids = X_test[id_col]\n",
    "X_test = X_test.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "X_test.drop(columns=all_missing, errors='ignore', inplace=True)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "raw_preds = model.predict(X_test_proc)\n",
    "final = np.expm1(np.clip(raw_preds, a_min=None, a_max=20)) if np.all(raw_preds >= 0) else raw_preds\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1, 1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Tuner - 1 Attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 06m 56s]\n",
      "val_loss: 0.2960398197174072\n",
      "\n",
      "Best val_loss So Far: 0.29548490047454834\n",
      "Total elapsed time: 01h 12m 03s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714/4714 - 25s - 5ms/step - loss: 0.5426 - mse_real: 19172701023995166720.0000 - rmse_real: 63838284.0000 - val_loss: 0.3063 - val_mse_real: 4925497856.0000 - val_rmse_real: 43360.3750\n",
      "Epoch 2/100\n",
      "4714/4714 - 22s - 5ms/step - loss: 0.3697 - mse_real: 5990876160.0000 - rmse_real: 47075.2734 - val_loss: 0.3247 - val_mse_real: 4925643264.0000 - val_rmse_real: 43508.1875\n",
      "Epoch 3/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3542 - mse_real: 5944964608.0000 - rmse_real: 46533.6992 - val_loss: 0.3119 - val_mse_real: 5144035840.0000 - val_rmse_real: 44871.5352\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714/4714 - 19s - 4ms/step - loss: 0.3371 - mse_real: 5916884992.0000 - rmse_real: 46091.7656 - val_loss: 0.3036 - val_mse_real: 5115154432.0000 - val_rmse_real: 44498.7148\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714/4714 - 19s - 4ms/step - loss: 0.3297 - mse_real: 5901241856.0000 - rmse_real: 45843.6250 - val_loss: 0.2992 - val_mse_real: 5052323328.0000 - val_rmse_real: 43952.2188\n",
      "Epoch 6/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3282 - mse_real: 5895203328.0000 - rmse_real: 45743.3906 - val_loss: 0.2996 - val_mse_real: 5074844160.0000 - val_rmse_real: 44106.4375\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714/4714 - 19s - 4ms/step - loss: 0.3275 - mse_real: 6334534144.0000 - rmse_real: 46041.8242 - val_loss: 0.2984 - val_mse_real: 5046730752.0000 - val_rmse_real: 43879.6328\n",
      "Epoch 8/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3282 - mse_real: 35256508416.0000 - rmse_real: 48195.7812 - val_loss: 0.3021 - val_mse_real: 5043734016.0000 - val_rmse_real: 43862.6367\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714/4714 - 19s - 4ms/step - loss: 0.3260 - mse_real: 206684094464.0000 - rmse_real: 52200.8125 - val_loss: 0.2979 - val_mse_real: 5046713856.0000 - val_rmse_real: 43860.0586\n",
      "Epoch 10/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3243 - mse_real: 5889111040.0000 - rmse_real: 45621.6250 - val_loss: 0.2986 - val_mse_real: 5057114624.0000 - val_rmse_real: 43981.4844\n",
      "Epoch 11/100\n",
      "4714/4714 - 22s - 5ms/step - loss: 0.3243 - mse_real: 5888558592.0000 - rmse_real: 45612.1875 - val_loss: 0.2984 - val_mse_real: 5019281920.0000 - val_rmse_real: 43655.7344\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714/4714 - 24s - 5ms/step - loss: 0.3236 - mse_real: 5881847808.0000 - rmse_real: 45615.9648 - val_loss: 0.2979 - val_mse_real: 5053080064.0000 - val_rmse_real: 43917.9727\n",
      "Epoch 13/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3222 - mse_real: 5877618176.0000 - rmse_real: 45570.4023 - val_loss: 0.3002 - val_mse_real: 5052841472.0000 - val_rmse_real: 43934.1055\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4714/4714 - 19s - 4ms/step - loss: 0.3367 - mse_real: inf - rmse_real: inf - val_loss: 0.2973 - val_mse_real: 5051807232.0000 - val_rmse_real: 43904.5469\n",
      "Epoch 15/100\n",
      "4714/4714 - 21s - 4ms/step - loss: 0.3209 - mse_real: 6154395648.0000 - rmse_real: 45757.2773 - val_loss: 0.2973 - val_mse_real: 5021539328.0000 - val_rmse_real: 43657.0742\n",
      "Epoch 16/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3208 - mse_real: 5882513408.0000 - rmse_real: 45519.6992 - val_loss: 0.3023 - val_mse_real: 5106527232.0000 - val_rmse_real: 44417.0000\n",
      "Epoch 17/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3199 - mse_real: 5876698112.0000 - rmse_real: 45511.1758 - val_loss: 0.2999 - val_mse_real: 5076005888.0000 - val_rmse_real: 44124.5391\n",
      "Epoch 18/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3197 - mse_real: 5876789248.0000 - rmse_real: 45519.0508 - val_loss: 0.2983 - val_mse_real: 5067098112.0000 - val_rmse_real: 44028.4297\n",
      "Epoch 19/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3189 - mse_real: 5876754432.0000 - rmse_real: 45482.3867 - val_loss: 0.2968 - val_mse_real: 5049546752.0000 - val_rmse_real: 43879.9883\n",
      "Epoch 20/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3181 - mse_real: 5871878144.0000 - rmse_real: 45430.3320 - val_loss: 0.3030 - val_mse_real: 5113052160.0000 - val_rmse_real: 44478.0625\n",
      "Epoch 21/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3183 - mse_real: 5873110528.0000 - rmse_real: 45501.1641 - val_loss: 0.2987 - val_mse_real: 5067447808.0000 - val_rmse_real: 44025.3867\n",
      "Epoch 22/100\n",
      "4714/4714 - 20s - 4ms/step - loss: 0.3176 - mse_real: 5872584704.0000 - rmse_real: 45440.0273 - val_loss: 0.2981 - val_mse_real: 5056776704.0000 - val_rmse_real: 43920.1680\n",
      "Epoch 23/100\n",
      "4714/4714 - 20s - 4ms/step - loss: 0.3168 - mse_real: 5873696256.0000 - rmse_real: 45425.5938 - val_loss: 0.3003 - val_mse_real: 5097873920.0000 - val_rmse_real: 44330.6445\n",
      "Epoch 24/100\n",
      "4714/4714 - 20s - 4ms/step - loss: 0.3167 - mse_real: 5872465920.0000 - rmse_real: 45394.5977 - val_loss: 0.2986 - val_mse_real: 5073551360.0000 - val_rmse_real: 44087.6250\n",
      "Epoch 25/100\n",
      "4714/4714 - 20s - 4ms/step - loss: 0.3174 - mse_real: 5877816320.0000 - rmse_real: 45480.4805 - val_loss: 0.2991 - val_mse_real: 5073741824.0000 - val_rmse_real: 44091.9375\n",
      "Epoch 26/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3163 - mse_real: 5870517248.0000 - rmse_real: 45409.4023 - val_loss: 0.2977 - val_mse_real: 5023055360.0000 - val_rmse_real: 43653.6250\n",
      "Epoch 27/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3162 - mse_real: 5868240896.0000 - rmse_real: 45373.4766 - val_loss: 0.2973 - val_mse_real: 5047751680.0000 - val_rmse_real: 43858.8008\n",
      "Epoch 28/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3170 - mse_real: 2346830528512000.0000 - rmse_real: 750982.9375 - val_loss: 0.2966 - val_mse_real: 5049304576.0000 - val_rmse_real: 43852.7461\n",
      "Epoch 29/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3161 - mse_real: 5873305600.0000 - rmse_real: 45399.6328 - val_loss: 0.3006 - val_mse_real: 5053351424.0000 - val_rmse_real: 43891.8555\n",
      "Epoch 30/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3148 - mse_real: 5868788736.0000 - rmse_real: 45376.0469 - val_loss: 0.2985 - val_mse_real: 5075160064.0000 - val_rmse_real: 44088.5898\n",
      "Epoch 31/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3302 - mse_real: inf - rmse_real: inf - val_loss: 0.2981 - val_mse_real: 5051656704.0000 - val_rmse_real: 43890.8242\n",
      "Epoch 32/100\n",
      "4714/4714 - 19s - 4ms/step - loss: 0.3141 - mse_real: 5869511168.0000 - rmse_real: 45328.8984 - val_loss: 0.2991 - val_mse_real: 5061848064.0000 - val_rmse_real: 44014.1797\n",
      "Epoch 33/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3144 - mse_real: 5870527488.0000 - rmse_real: 45357.6406 - val_loss: 0.2987 - val_mse_real: 5063622144.0000 - val_rmse_real: 44041.6914\n",
      "Epoch 34/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3129 - mse_real: 5862056960.0000 - rmse_real: 45291.0312 - val_loss: 0.2981 - val_mse_real: 5039104000.0000 - val_rmse_real: 43757.2852\n",
      "Epoch 35/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3139 - mse_real: 5870810624.0000 - rmse_real: 45346.7422 - val_loss: 0.2994 - val_mse_real: 5057774080.0000 - val_rmse_real: 43917.7891\n",
      "Epoch 36/100\n",
      "4714/4714 - 20s - 4ms/step - loss: 0.3139 - mse_real: 5870610432.0000 - rmse_real: 45342.4805 - val_loss: 0.2983 - val_mse_real: 5068124672.0000 - val_rmse_real: 44045.9297\n",
      "Epoch 37/100\n",
      "4714/4714 - 20s - 4ms/step - loss: 0.3134 - mse_real: 5873018368.0000 - rmse_real: 45359.3320 - val_loss: 0.2971 - val_mse_real: 5074274304.0000 - val_rmse_real: 44089.5781\n",
      "Epoch 38/100\n",
      "4714/4714 - 18s - 4ms/step - loss: 0.3127 - mse_real: 5862005248.0000 - rmse_real: 45319.4180 - val_loss: 0.2968 - val_mse_real: 5049714176.0000 - val_rmse_real: 43876.8633\n",
      "\u001b[1m3928/3928\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Reproducibility\n",
    "import os, random, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# Data Loading\n",
    "train_df = pd.read_csv('playground-series-s4e9/train.csv.zip')\n",
    "test_df = pd.read_csv('playground-series-s4e9/test.csv.zip')\n",
    "sample_sub = pd.read_csv('playground-series-s4e9/sample_submission.csv.zip', nrows=1)\n",
    "\n",
    "# Infer ID and target columns\n",
    "cols = list(sample_sub.columns)\n",
    "id_col = cols[0]\n",
    "target_columns = cols[1:]\n",
    "\n",
    "# Combine training data\n",
    "df = train_df.copy()\n",
    "\n",
    "# Target encoding for continuous regression\n",
    "y_values = df[target_columns].astype(float).values\n",
    "if np.all(y_values >= 0):\n",
    "    y_enc = np.log1p(y_values)\n",
    "else:\n",
    "    y_enc = y_values\n",
    "\n",
    "# Features\n",
    "X = df.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y_enc,\n",
    "    test_size=0.2,\n",
    "    random_state=seed\n",
    ")\n",
    "\n",
    "# Optional: drop ID from features\n",
    "for df_ in (X_train, X_val):\n",
    "    if id_col in df_.columns:\n",
    "        df_.drop(columns=[id_col], inplace=True)\n",
    "\n",
    "# Drop all-missing columns\n",
    "all_missing = [c for c in X_train.columns if X_train[c].isna().all()]\n",
    "X_train.drop(columns=all_missing, inplace=True)\n",
    "X_val.drop(columns=all_missing, inplace=True)\n",
    "\n",
    "# Feature types\n",
    "numeric_features = X_train.select_dtypes(include=['int64','float64']).columns.tolist()\n",
    "cat_features = X_train.select_dtypes(include=['object','category']).columns.tolist()\n",
    "low_cardinality = [c for c in cat_features if X_train[c].nunique() <= 50]\n",
    "\n",
    "# Preprocessing pipelines\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('cat', cat_pipeline, low_cardinality)\n",
    "])\n",
    "\n",
    "# Fit and transform\n",
    "X_train_proc = preprocessor.fit_transform(X_train)\n",
    "X_val_proc = preprocessor.transform(X_val)\n",
    "\n",
    "# Model architecture determination\n",
    "n_samples, n_features = X_train_proc.shape\n",
    "n_targets = y_train.shape[1] if y_train.ndim > 1 else 1\n",
    "\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError, MeanAbsoluteError\n",
    "\n",
    "# Define early stopping and checkpointing\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# Input dimension\n",
    "n_features = X_train_proc.shape[1]\n",
    "\n",
    "def mse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "mse_real.__name__ = 'mse_real'      \n",
    "\n",
    "def rmse_real(y_true_log, y_pred_log):\n",
    "    y_true = tf.math.expm1(y_true_log)\n",
    "    y_pred = tf.math.expm1(y_pred_log)\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_true - y_pred)))\n",
    "rmse_real.__name__ = 'rmse_real'\n",
    "\n",
    "# HyperModel\n",
    "class MyHyperModel(kt.HyperModel):\n",
    "    def build(self, hp):\n",
    "        layers = hp.Int('layers', 2, 8)\n",
    "        units = hp.Int('units', 64, 1024)\n",
    "        drop = hp.Float('dropout', 0.0, 0.5)\n",
    "        opt = hp.Choice('optimizer', ['adam'])\n",
    "        lr = hp.Float('learning_rate', 1e-5, 0.01, sampling='log')\n",
    "\n",
    "        model = Sequential()\n",
    "        for idx in range(layers):\n",
    "            if idx == 0:\n",
    "                model.add(Dense(units, activation='relu', input_dim=n_features))\n",
    "            else:\n",
    "                model.add(Dense(units, activation='relu'))\n",
    "            model.add(Dropout(drop))\n",
    "        model.add(Dense(1, activation='linear'))  # Assuming n_targets = 1 for regression\n",
    "\n",
    "        model.compile(optimizer=opt, loss='mean_squared_error', metrics=[rmse_real,mse_real])\n",
    "        return model\n",
    "\n",
    "# Tuner\n",
    "bs = 32  # batch size\n",
    "ep = 20  # epochs\n",
    "\n",
    "tuner = kt.BayesianOptimization(\n",
    "    MyHyperModel(),\n",
    "    objective='val_loss',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=1,\n",
    "    seed=42,\n",
    "    overwrite=False,\n",
    "    project_name='bayesian_tuner'\n",
    ")\n",
    "\n",
    "if y_val is not None:\n",
    "    tuner.search(\n",
    "        X_train_proc, y_train,\n",
    "        validation_data=(X_val_proc, y_val),\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "else:\n",
    "    tuner.search(\n",
    "        X_train_proc, y_train,\n",
    "        validation_split=0.2,\n",
    "        batch_size=bs, epochs=ep,\n",
    "        callbacks=[early_stopping, checkpoint]\n",
    "    )\n",
    "\n",
    "model = tuner.hypermodel.build(tuner.get_best_hyperparameters(1)[0])\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Retrain model with original callbacks and data\n",
    "if y_val is not None:\n",
    "    history = model.fit(\n",
    "        X_train_proc, y_train,\n",
    "        validation_data=(X_val_proc, y_val),\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "else:\n",
    "    history = model.fit(\n",
    "        X_train_proc, y_train,\n",
    "        validation_split=0.2,\n",
    "        epochs=100, batch_size=bs,\n",
    "        callbacks=[early_stopping, checkpoint],\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "duration = time.time() - start_time\n",
    "\n",
    "\n",
    "# Logging results\n",
    "results = {\n",
    "    'training_loss': history.history['mse_real'][-1],\n",
    "    'validation_loss': history.history['val_mse_real'][-1],\n",
    "    'training_RMSE': history.history['rmse_real'][-1],\n",
    "    'validation_RMSE': history.history['val_rmse_real'][-1]\n",
    "}\n",
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results, f)\n",
    "\n",
    "# Prediction & Submission\n",
    "X_test = test_df.copy()\n",
    "if id_col in X_test.columns:\n",
    "    test_ids = X_test[id_col]\n",
    "X_test = X_test.drop(columns=target_columns + [id_col], errors='ignore')\n",
    "X_test.drop(columns=all_missing, errors='ignore', inplace=True)\n",
    "X_test_proc = preprocessor.transform(X_test)\n",
    "raw_preds = model.predict(X_test_proc)\n",
    "final = np.expm1(np.clip(raw_preds, a_min=None, a_max=20)) if np.all(raw_preds >= 0) else raw_preds\n",
    "if final.ndim == 1:\n",
    "    final = final.reshape(-1, 1)\n",
    "submission = pd.DataFrame(final, columns=target_columns)\n",
    "submission.insert(0, id_col, test_ids.reset_index(drop=True))\n",
    "submission.to_csv('submission_result.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736.234264\n"
     ]
    }
   ],
   "source": [
    "print(duration)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
